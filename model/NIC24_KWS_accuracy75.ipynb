{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkd5EABaGJFY",
        "outputId": "f16de6b3-2e80-45e0-9cfe-42dbf8ae77b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.5/107.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tonic --quiet\n",
        "!pip install snntorch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SjmSndG5Fgnf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "import torchvision\n",
        "# import torchvision.transforms as transforms\n",
        "from tonic import datasets, transforms\n",
        "\n",
        "import tonic\n",
        "import snntorch as snn\n",
        "from snntorch import functional as SF\n",
        "\n",
        "from tonic import DiskCachedDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtC5R5NyT-qT",
        "outputId": "641a78c6-3e33-400a-c50e-ff893568ff73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zEbJ2rqSFkYy"
      },
      "outputs": [],
      "source": [
        "# Define the fully connected network\n",
        "\n",
        "class FCN_1(nn.Module):\n",
        "    def __init__(self, neurons_in=700, neurons_h1=256, bn=False, dropout=0.0, beta=0.95):\n",
        "        super(FCN_1, self).__init__()\n",
        "        self.fc1 = nn.Linear(neurons_in, neurons_h1)\n",
        "        self.fc_ = nn.Linear(neurons_h1, 20)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.lif_ = snn.Leaky(beta=beta)\n",
        "        if dropout > 0:\n",
        "          self.drop1 = nn.Dropout(p=dropout)\n",
        "        if bn:\n",
        "          self.bn1 = nn.BatchNorm1d(neurons_h1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      spk_rec = []\n",
        "      mem_rec = []\n",
        "\n",
        "      mem1 = self.lif1.init_leaky()\n",
        "      mem_ = self.lif_.init_leaky()\n",
        "\n",
        "      for step in range(x.size(0)):\n",
        "        cur1 = self.fc1(x[step].squeeze(1))\n",
        "        if hasattr(self, 'drop1'):\n",
        "          cur1 = self.drop1(cur1)\n",
        "        if hasattr(self, 'bn1'):\n",
        "          cur1 = self.bn1(cur1)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "        cur_ = self.fc_(spk1)\n",
        "        spk_, mem_ = self.lif_(cur_, mem_)\n",
        "        spk_rec.append(spk_)\n",
        "        mem_rec.append(mem_)\n",
        "      return torch.stack(spk_rec), torch.stack(mem_rec)\n",
        "\n",
        "class FCN_2(nn.Module):\n",
        "    def __init__(self, neurons_in=700, neurons_h1=256, neurons_h2=256, bn=False, dropout=0.0, beta=0.95):\n",
        "        super(FCN_2, self).__init__()\n",
        "        self.fc1 = nn.Linear(neurons_in, neurons_h1)\n",
        "        self.fc2 = nn.Linear(neurons_h1, neurons_h2)\n",
        "        self.fc_ = nn.Linear(neurons_h2, 20)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.lif_ = snn.Leaky(beta=beta)\n",
        "        if dropout > 0:\n",
        "          self.drop1 = nn.Dropout(p=dropout)\n",
        "          self.drop2 = nn.Dropout(p=dropout)\n",
        "        if bn:\n",
        "          self.bn1 = nn.BatchNorm1d(neurons_h1)\n",
        "          self.bn2 = nn.BatchNorm1d(neurons_h2)\n",
        "\n",
        "    def forward(self, x):\n",
        "      spk_rec = []\n",
        "      mem_rec = []\n",
        "\n",
        "      mem1 = self.lif1.init_leaky()\n",
        "      mem2 = self.lif2.init_leaky()\n",
        "      mem_ = self.lif_.init_leaky()\n",
        "\n",
        "      for step in range(x.size(0)):\n",
        "        cur1 = self.fc1(x[step].squeeze(1))\n",
        "        if hasattr(self, 'drop1'):\n",
        "          cur1 = self.drop1(cur1)\n",
        "        if hasattr(self, 'bn1'):\n",
        "          cur1 = self.bn1(cur1)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "        cur2 = self.fc2(spk1)\n",
        "        if hasattr(self, 'drop2'):\n",
        "          cur2 = self.drop2(cur2)\n",
        "        if hasattr(self, 'bn2'):\n",
        "          cur2 = self.bn2(cur2)\n",
        "        spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "        cur_ = self.fc_(spk2)\n",
        "        spk_, mem_ = self.lif_(cur_, mem_)\n",
        "        spk_rec.append(spk_)\n",
        "        mem_rec.append(mem_)\n",
        "      return torch.stack(spk_rec), torch.stack(mem_rec)\n",
        "\n",
        "class FCN_3(nn.Module):\n",
        "    def __init__(self, neurons_in=700, neurons_h1=256, neurons_h2=256, neurons_h3=256, bn=False, dropout=0.0, beta=0.95):\n",
        "        super(FCN_3, self).__init__()\n",
        "        self.fc1 = nn.Linear(neurons_in, neurons_h1)\n",
        "        self.fc2 = nn.Linear(neurons_h1, neurons_h2)\n",
        "        self.fc3 = nn.Linear(neurons_h2, neurons_h3)\n",
        "        self.fc_ = nn.Linear(neurons_h3, 20)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.lif3 = snn.Leaky(beta=beta)\n",
        "        self.lif_ = snn.Leaky(beta=beta)\n",
        "        if dropout > 0:\n",
        "          self.drop1 = nn.Dropout(p=dropout)\n",
        "          self.drop2 = nn.Dropout(p=dropout)\n",
        "          self.drop3 = nn.Dropout(p=dropout)\n",
        "        if bn:\n",
        "          self.bn1 = nn.BatchNorm1d(neurons_h1)\n",
        "          self.bn2 = nn.BatchNorm1d(neurons_h2)\n",
        "          self.bn3 = nn.BatchNorm1d(neurons_h3)\n",
        "\n",
        "    def forward(self, x):\n",
        "      spk_rec = []\n",
        "      mem_rec = []\n",
        "\n",
        "      mem1 = self.lif1.init_leaky()\n",
        "      mem2 = self.lif2.init_leaky()\n",
        "      mem3 = self.lif2.init_leaky()\n",
        "      mem_ = self.lif_.init_leaky()\n",
        "\n",
        "      for step in range(x.size(0)):\n",
        "        cur1 = self.fc1(x[step].squeeze(1))\n",
        "        if hasattr(self, 'drop1'):\n",
        "          cur1 = self.drop1(cur1)\n",
        "        if hasattr(self, 'bn1'):\n",
        "          cur1 = self.bn1(cur1)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "        cur2 = self.fc2(spk1)\n",
        "        if hasattr(self, 'drop2'):\n",
        "          cur2 = self.drop2(cur2)\n",
        "        if hasattr(self, 'bn2'):\n",
        "          cur2 = self.bn2(cur2)\n",
        "        spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "        cur3 = self.fc3(spk2)\n",
        "        if hasattr(self, 'drop3'):\n",
        "          cur3 = self.drop3(cur3)\n",
        "        if hasattr(self, 'bn3'):\n",
        "          cur3 = self.bn3(cur3)\n",
        "        spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "        cur_ = self.fc_(spk3)\n",
        "        spk_, mem_ = self.lif_(cur_, mem_)\n",
        "        spk_rec.append(spk_)\n",
        "        mem_rec.append(mem_)\n",
        "      return torch.stack(spk_rec), torch.stack(mem_rec)\n",
        "\n",
        "\n",
        "class FCN_4(nn.Module):\n",
        "    def __init__(self, neurons_in=700, neurons_h1=256, neurons_h2=256, neurons_h3=256, neurons_h4=256, bn=False, dropout=0.0, beta=0.95):\n",
        "        super(FCN_4, self).__init__()\n",
        "        self.fc1 = nn.Linear(neurons_in, neurons_h1)\n",
        "        self.fc2 = nn.Linear(neurons_h1, neurons_h2)\n",
        "        self.fc3 = nn.Linear(neurons_h3, neurons_h3)\n",
        "        self.fc4 = nn.Linear(neurons_h3, neurons_h4)\n",
        "        self.fc_ = nn.Linear(neurons_h4, 20)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.lif2 = snn.Leaky(beta=beta)\n",
        "        self.lif3 = snn.Leaky(beta=beta)\n",
        "        self.lif4 = snn.Leaky(beta=beta)\n",
        "        self.lif_ = snn.Leaky(beta=beta)\n",
        "        if dropout > 0:\n",
        "          self.drop1 = nn.Dropout(p=dropout)\n",
        "          self.drop2 = nn.Dropout(p=dropout)\n",
        "          self.drop3 = nn.Dropout(p=dropout)\n",
        "          self.drop4 = nn.Dropout(p=dropout)\n",
        "        if bn:\n",
        "          self.bn1 = nn.BatchNorm1d(neurons_h1)\n",
        "          self.bn2 = nn.BatchNorm1d(neurons_h2)\n",
        "          self.bn3 = nn.BatchNorm1d(neurons_h3)\n",
        "          self.bn4 = nn.BatchNorm1d(neurons_h4)\n",
        "\n",
        "    def forward(self, x):\n",
        "      spk_rec = []\n",
        "      mem_rec = []\n",
        "\n",
        "      mem1 = self.lif1.init_leaky()\n",
        "      mem2 = self.lif2.init_leaky()\n",
        "      mem3 = self.lif2.init_leaky()\n",
        "      mem4 = self.lif2.init_leaky()\n",
        "      mem_ = self.lif_.init_leaky()\n",
        "\n",
        "      for step in range(x.size(0)):\n",
        "        cur1 = self.fc1(x[step].squeeze(1))\n",
        "        if hasattr(self, 'drop1'):\n",
        "          cur1 = self.drop1(cur1)\n",
        "        if hasattr(self, 'bn1'):\n",
        "          cur1 = self.bn1(cur1)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "        cur2 = self.fc2(spk1)\n",
        "        if hasattr(self, 'drop2'):\n",
        "          cur2 = self.drop2(cur2)\n",
        "        if hasattr(self, 'bn2'):\n",
        "          cur2 = self.bn2(cur2)\n",
        "        spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "        cur3 = self.fc3(spk2)\n",
        "        if hasattr(self, 'drop3'):\n",
        "          cur3 = self.drop3(cur3)\n",
        "        if hasattr(self, 'bn3'):\n",
        "          cur3 = self.bn3(cur3)\n",
        "        spk3, mem3 = self.lif3(cur3, mem3)\n",
        "\n",
        "        cur4 = self.fc4(spk3)\n",
        "        if hasattr(self, 'drop4'):\n",
        "          cur4 = self.drop4(cur4)\n",
        "        if hasattr(self, 'bn4'):\n",
        "          cur4 = self.bn4(cur4)\n",
        "        spk4, mem4 = self.lif4(cur4, mem4)\n",
        "\n",
        "        cur_ = self.fc_(spk4)\n",
        "        spk_, mem_ = self.lif_(cur_, mem_)\n",
        "        spk_rec.append(spk_)\n",
        "        mem_rec.append(mem_)\n",
        "      return torch.stack(spk_rec), torch.stack(mem_rec)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "PFC7N2U8eBpn"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, trainloader, device, num_epochs=30, testloader=None, scheduler=None):\n",
        "  t = time.process_time()\n",
        "  for epoch in range(num_epochs):\n",
        "      # Training loop\n",
        "      model.train()\n",
        "      for batch_idx, (data, target) in enumerate(trainloader):\n",
        "          optimizer.zero_grad()\n",
        "          spk_rec, mem_rec = model(data.to(device))\n",
        "          # spk_rec = model(data.to(device))[-1]\n",
        "          loss = criterion(spk_rec, target.to(device))\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if batch_idx % 100 == 0:\n",
        "              print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(trainloader)}], Loss: {loss.item():.4f}')\n",
        "      # if scheduler is not None:\n",
        "      #     model.eval()\n",
        "      #     correct = 0\n",
        "      #     total = 0\n",
        "      #     for data, target in testloader:\n",
        "      #         spk_rec, mem_rec = model(data.to(device))\n",
        "      #         correct += SF.accuracy_rate(spk_rec, target.to(device)) * target.size(0)\n",
        "      #         total += spk_rec.size(1)\n",
        "      #     scheduler.step(correct / total)\n",
        "      if scheduler is not None:\n",
        "          scheduler.step()\n",
        "      if epoch % 10 == 0 and testloader is not None:\n",
        "          accuracy(model, testloader, device)\n",
        "  print(f'Training time: {time.process_time() - t}')\n",
        "\n",
        "\n",
        "def accuracy(model, testloader, device):\n",
        "    # Testing loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        correct2 = 0\n",
        "        total2 = 0\n",
        "        for data, target in testloader:\n",
        "            spk_rec, mem_rec = model(data.to(device))\n",
        "            # spk_rec = model(data.to(device))[-1]\n",
        "            # print('input: ', data.size(), ' output: ', spk_rec.size())\n",
        "            correct += SF.accuracy_rate(spk_rec, target.to(device)) * target.size(0)\n",
        "            total += spk_rec.size(1)\n",
        "            total2 += target.size(0)\n",
        "            # print(correct, ' out of ', target.size())\n",
        "\n",
        "            # correct2 += (predicted == target).sum().item()\n",
        "\n",
        "        print(f'Accuracy of the network on test set: {100 * correct / total:.2f}% ({100 * correct / total2:.2f}%)')\n",
        "\n",
        "def accuracy_2class(model, testloader, device):\n",
        "    # Testing loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data, target in testloader:\n",
        "            spk_rec, mem_rec = model(data.to(device))\n",
        "            _, idx = spk_rec.sum(dim=0).max(1)\n",
        "            idx = (idx < 10)\n",
        "            target = (target.to(device) < 10)\n",
        "            equal = (target.to(device) == idx.to(device)).detach().cpu().numpy()\n",
        "            correct += np.mean(equal) * target.size(0)\n",
        "            total += target.size(0)\n",
        "        print(f'Accuracy of the network on 2 classes: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jApriJk6-FaR",
        "outputId": "040e2941-222f-42c8-e730-2b342664075f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256, 1, 512]) torch.Size([256]) tensor([19,  7, 15, 14,  3, 14,  7, 11,  0, 19, 17,  7,  9,  0,  8,  0, 16, 17,\n",
            "        15,  5, 15, 10,  1,  9, 11, 19, 16,  4, 19, 18, 16,  6,  5, 18, 15, 13,\n",
            "        12, 11, 19,  5, 16,  3,  8,  3,  2, 14, 13, 14,  2,  0, 10, 19, 16,  0,\n",
            "         7,  6,  3,  3, 11,  4, 19,  5,  6,  0, 17, 15,  9,  1,  6, 19, 15,  6,\n",
            "        14,  7,  0, 10,  5,  6,  2, 17, 17, 15, 11,  7, 15,  9,  5, 14,  1, 16,\n",
            "         5,  5, 15,  2, 19, 13,  3, 12,  6, 10,  3, 17,  6,  8, 17,  6, 15,  7,\n",
            "        17, 11,  6,  3,  4,  1, 19, 14,  4,  3, 19, 10,  9,  7, 10, 17, 12, 17,\n",
            "         6, 11,  3, 17,  1, 13,  8, 11,  2, 11, 11,  2,  7, 15, 17,  6, 16, 18,\n",
            "         6, 17,  2,  4, 14, 17,  0, 16, 12, 14,  1,  0,  1,  4,  7,  0,  3, 17,\n",
            "         4,  1,  0,  5, 19,  6,  7, 19,  2, 11,  5, 19,  4,  2, 15, 19,  5,  2,\n",
            "        17, 15,  5, 11, 13,  4,  6,  1,  7, 16, 10, 14,  1,  1,  4,  3,  3,  1,\n",
            "        18,  5, 19, 16, 16,  0,  2, 13,  6,  6,  4,  2, 14, 13,  6, 14,  6,  4,\n",
            "         6, 10, 11,  2, 19,  3, 14,  7, 15,  9,  0, 12,  8, 15,  9, 19,  2, 11,\n",
            "        16,  0, 13, 18, 18,  3,  0,  6,  8, 19, 18,  4,  8, 12,  6, 19,  5, 11,\n",
            "        19,  9, 19, 19])\n",
            "Epoch [1/150], Step [1/32], Loss: 3.0147\n",
            "Accuracy of the network on test set: 29.37% (29.37%)\n",
            "Epoch [2/150], Step [1/32], Loss: 2.8694\n",
            "Epoch [3/150], Step [1/32], Loss: 2.6675\n",
            "Epoch [4/150], Step [1/32], Loss: 2.5859\n",
            "Epoch [5/150], Step [1/32], Loss: 2.5741\n",
            "Epoch [6/150], Step [1/32], Loss: 2.5540\n",
            "Epoch [7/150], Step [1/32], Loss: 2.5228\n",
            "Epoch [8/150], Step [1/32], Loss: 2.4956\n",
            "Epoch [9/150], Step [1/32], Loss: 2.5211\n",
            "Epoch [10/150], Step [1/32], Loss: 2.4659\n",
            "Epoch [11/150], Step [1/32], Loss: 2.4503\n",
            "Accuracy of the network on test set: 53.67% (53.67%)\n",
            "Epoch [12/150], Step [1/32], Loss: 2.4556\n",
            "Epoch [13/150], Step [1/32], Loss: 2.4427\n",
            "Epoch [14/150], Step [1/32], Loss: 2.4380\n",
            "Epoch [15/150], Step [1/32], Loss: 2.4207\n",
            "Epoch [16/150], Step [1/32], Loss: 2.4124\n",
            "Epoch [17/150], Step [1/32], Loss: 2.4204\n",
            "Epoch [18/150], Step [1/32], Loss: 2.4206\n",
            "Epoch [19/150], Step [1/32], Loss: 2.3929\n",
            "Epoch [20/150], Step [1/32], Loss: 2.3919\n",
            "Epoch [21/150], Step [1/32], Loss: 2.3717\n",
            "Accuracy of the network on test set: 63.38% (63.38%)\n",
            "Epoch [22/150], Step [1/32], Loss: 2.3612\n",
            "Epoch [23/150], Step [1/32], Loss: 2.3678\n",
            "Epoch [24/150], Step [1/32], Loss: 2.3943\n",
            "Epoch [25/150], Step [1/32], Loss: 2.3572\n",
            "Epoch [26/150], Step [1/32], Loss: 2.3509\n",
            "Epoch [27/150], Step [1/32], Loss: 2.3622\n",
            "Epoch [28/150], Step [1/32], Loss: 2.3381\n",
            "Epoch [29/150], Step [1/32], Loss: 2.3449\n",
            "Epoch [30/150], Step [1/32], Loss: 2.3622\n",
            "Epoch [31/150], Step [1/32], Loss: 2.3595\n",
            "Accuracy of the network on test set: 65.28% (65.28%)\n",
            "Epoch [32/150], Step [1/32], Loss: 2.3386\n",
            "Epoch [33/150], Step [1/32], Loss: 2.3346\n",
            "Epoch [34/150], Step [1/32], Loss: 2.3398\n",
            "Epoch [35/150], Step [1/32], Loss: 2.3346\n",
            "Epoch [36/150], Step [1/32], Loss: 2.3276\n",
            "Epoch [37/150], Step [1/32], Loss: 2.3543\n",
            "Epoch [38/150], Step [1/32], Loss: 2.3279\n",
            "Epoch [39/150], Step [1/32], Loss: 2.3308\n",
            "Epoch [40/150], Step [1/32], Loss: 2.3391\n",
            "Epoch [41/150], Step [1/32], Loss: 2.3164\n",
            "Accuracy of the network on test set: 69.35% (69.35%)\n",
            "Epoch [42/150], Step [1/32], Loss: 2.3255\n",
            "Epoch [43/150], Step [1/32], Loss: 2.3007\n",
            "Epoch [44/150], Step [1/32], Loss: 2.3127\n",
            "Epoch [45/150], Step [1/32], Loss: 2.3104\n",
            "Epoch [46/150], Step [1/32], Loss: 2.3083\n",
            "Epoch [47/150], Step [1/32], Loss: 2.3082\n",
            "Epoch [48/150], Step [1/32], Loss: 2.3176\n",
            "Epoch [49/150], Step [1/32], Loss: 2.2877\n",
            "Epoch [50/150], Step [1/32], Loss: 2.2980\n",
            "Epoch [51/150], Step [1/32], Loss: 2.2983\n",
            "Accuracy of the network on test set: 69.61% (69.61%)\n",
            "Epoch [52/150], Step [1/32], Loss: 2.2963\n",
            "Epoch [53/150], Step [1/32], Loss: 2.2940\n",
            "Epoch [54/150], Step [1/32], Loss: 2.2966\n",
            "Epoch [55/150], Step [1/32], Loss: 2.2895\n",
            "Epoch [56/150], Step [1/32], Loss: 2.2991\n",
            "Epoch [57/150], Step [1/32], Loss: 2.2859\n",
            "Epoch [58/150], Step [1/32], Loss: 2.2972\n",
            "Epoch [59/150], Step [1/32], Loss: 2.2909\n",
            "Epoch [60/150], Step [1/32], Loss: 2.2912\n",
            "Epoch [61/150], Step [1/32], Loss: 2.2824\n",
            "Accuracy of the network on test set: 70.58% (70.58%)\n",
            "Epoch [62/150], Step [1/32], Loss: 2.2907\n",
            "Epoch [63/150], Step [1/32], Loss: 2.2834\n",
            "Epoch [64/150], Step [1/32], Loss: 2.2884\n",
            "Epoch [65/150], Step [1/32], Loss: 2.2843\n",
            "Epoch [66/150], Step [1/32], Loss: 2.2821\n",
            "Epoch [67/150], Step [1/32], Loss: 2.2798\n",
            "Epoch [68/150], Step [1/32], Loss: 2.2864\n",
            "Epoch [69/150], Step [1/32], Loss: 2.2908\n",
            "Epoch [70/150], Step [1/32], Loss: 2.3110\n",
            "Epoch [71/150], Step [1/32], Loss: 2.2802\n",
            "Accuracy of the network on test set: 70.05% (70.05%)\n",
            "Epoch [72/150], Step [1/32], Loss: 2.2638\n",
            "Epoch [73/150], Step [1/32], Loss: 2.2639\n",
            "Epoch [74/150], Step [1/32], Loss: 2.2579\n",
            "Epoch [75/150], Step [1/32], Loss: 2.2640\n",
            "Epoch [76/150], Step [1/32], Loss: 2.2566\n",
            "Epoch [77/150], Step [1/32], Loss: 2.2758\n",
            "Epoch [78/150], Step [1/32], Loss: 2.2678\n",
            "Epoch [79/150], Step [1/32], Loss: 2.2581\n",
            "Epoch [80/150], Step [1/32], Loss: 2.2552\n",
            "Epoch [81/150], Step [1/32], Loss: 2.2725\n",
            "Accuracy of the network on test set: 71.20% (71.20%)\n",
            "Epoch [82/150], Step [1/32], Loss: 2.2689\n",
            "Epoch [83/150], Step [1/32], Loss: 2.2638\n",
            "Epoch [84/150], Step [1/32], Loss: 2.2612\n",
            "Epoch [85/150], Step [1/32], Loss: 2.2707\n",
            "Epoch [86/150], Step [1/32], Loss: 2.2628\n",
            "Epoch [87/150], Step [1/32], Loss: 2.2599\n",
            "Epoch [88/150], Step [1/32], Loss: 2.2569\n",
            "Epoch [89/150], Step [1/32], Loss: 2.2596\n",
            "Epoch [90/150], Step [1/32], Loss: 2.2616\n",
            "Epoch [91/150], Step [1/32], Loss: 2.2626\n",
            "Accuracy of the network on test set: 70.58% (70.58%)\n",
            "Epoch [92/150], Step [1/32], Loss: 2.2658\n",
            "Epoch [93/150], Step [1/32], Loss: 2.2524\n",
            "Epoch [94/150], Step [1/32], Loss: 2.2641\n",
            "Epoch [95/150], Step [1/32], Loss: 2.2548\n",
            "Epoch [96/150], Step [1/32], Loss: 2.2448\n",
            "Epoch [97/150], Step [1/32], Loss: 2.2590\n",
            "Epoch [98/150], Step [1/32], Loss: 2.2674\n",
            "Epoch [99/150], Step [1/32], Loss: 2.2519\n",
            "Epoch [100/150], Step [1/32], Loss: 2.2554\n",
            "Epoch [101/150], Step [1/32], Loss: 2.2573\n",
            "Accuracy of the network on test set: 71.07% (71.07%)\n",
            "Epoch [102/150], Step [1/32], Loss: 2.2524\n",
            "Epoch [103/150], Step [1/32], Loss: 2.2538\n",
            "Epoch [104/150], Step [1/32], Loss: 2.2657\n",
            "Epoch [105/150], Step [1/32], Loss: 2.2512\n",
            "Epoch [106/150], Step [1/32], Loss: 2.2470\n",
            "Epoch [107/150], Step [1/32], Loss: 2.2643\n",
            "Epoch [108/150], Step [1/32], Loss: 2.2406\n",
            "Epoch [109/150], Step [1/32], Loss: 2.2559\n",
            "Epoch [110/150], Step [1/32], Loss: 2.2472\n",
            "Epoch [111/150], Step [1/32], Loss: 2.2525\n",
            "Accuracy of the network on test set: 70.41% (70.41%)\n",
            "Epoch [112/150], Step [1/32], Loss: 2.2582\n",
            "Epoch [113/150], Step [1/32], Loss: 2.2507\n",
            "Epoch [114/150], Step [1/32], Loss: 2.2530\n",
            "Epoch [115/150], Step [1/32], Loss: 2.2414\n",
            "Epoch [116/150], Step [1/32], Loss: 2.2455\n",
            "Epoch [117/150], Step [1/32], Loss: 2.2456\n",
            "Epoch [118/150], Step [1/32], Loss: 2.2578\n",
            "Epoch [119/150], Step [1/32], Loss: 2.2660\n",
            "Epoch [120/150], Step [1/32], Loss: 2.2421\n",
            "Epoch [121/150], Step [1/32], Loss: 2.2509\n",
            "Accuracy of the network on test set: 70.63% (70.63%)\n",
            "Epoch [122/150], Step [1/32], Loss: 2.2455\n",
            "Epoch [123/150], Step [1/32], Loss: 2.2491\n",
            "Epoch [124/150], Step [1/32], Loss: 2.2481\n",
            "Epoch [125/150], Step [1/32], Loss: 2.2486\n",
            "Epoch [126/150], Step [1/32], Loss: 2.2636\n",
            "Epoch [127/150], Step [1/32], Loss: 2.2518\n",
            "Epoch [128/150], Step [1/32], Loss: 2.2334\n",
            "Epoch [129/150], Step [1/32], Loss: 2.2512\n",
            "Epoch [130/150], Step [1/32], Loss: 2.2482\n",
            "Epoch [131/150], Step [1/32], Loss: 2.2542\n",
            "Accuracy of the network on test set: 70.85% (70.85%)\n",
            "Epoch [132/150], Step [1/32], Loss: 2.2408\n",
            "Epoch [133/150], Step [1/32], Loss: 2.2446\n",
            "Epoch [134/150], Step [1/32], Loss: 2.2442\n",
            "Epoch [135/150], Step [1/32], Loss: 2.2554\n",
            "Epoch [136/150], Step [1/32], Loss: 2.2376\n",
            "Epoch [137/150], Step [1/32], Loss: 2.2461\n",
            "Epoch [138/150], Step [1/32], Loss: 2.2394\n",
            "Epoch [139/150], Step [1/32], Loss: 2.2398\n",
            "Epoch [140/150], Step [1/32], Loss: 2.2505\n",
            "Epoch [141/150], Step [1/32], Loss: 2.2460\n",
            "Accuracy of the network on test set: 70.72% (70.72%)\n",
            "Epoch [142/150], Step [1/32], Loss: 2.2572\n",
            "Epoch [143/150], Step [1/32], Loss: 2.2511\n",
            "Epoch [144/150], Step [1/32], Loss: 2.2426\n",
            "Epoch [145/150], Step [1/32], Loss: 2.2384\n",
            "Epoch [146/150], Step [1/32], Loss: 2.2354\n",
            "Epoch [147/150], Step [1/32], Loss: 2.2577\n",
            "Epoch [148/150], Step [1/32], Loss: 2.2356\n",
            "Epoch [149/150], Step [1/32], Loss: 2.2439\n",
            "Epoch [150/150], Step [1/32], Loss: 2.2425\n",
            "Training time: 1656.7978279489998\n",
            "1656.7993244479994\n",
            "Accuracy of the network on test set: 70.63% (70.63%)\n",
            "Accuracy of the network on 2 classes: 82.46%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/2\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 150\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_1(neurons_in=512, neurons_h1=256, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)\n",
        "accuracy_2class(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeRKrAq5Kj1z",
        "outputId": "f77e12a1-09af-4e41-b119-67654ee56668"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256, 1, 512]) torch.Size([256]) tensor([17, 13, 19, 16,  8, 12,  4, 10, 18,  0,  4, 15,  1, 16, 14,  0,  0, 13,\n",
            "        19, 10, 18, 16,  1, 13,  5,  1, 11, 17, 15,  2, 10,  8,  1,  7, 12, 16,\n",
            "         7,  9,  7,  9, 13, 13,  8,  6,  2, 11, 19, 19, 17, 14,  2, 14, 17,  5,\n",
            "         8,  6, 10, 15,  7, 15,  2,  2,  5, 12, 12,  1, 10,  4,  6, 13,  5, 17,\n",
            "        19,  7, 19,  1, 14, 19,  7, 14, 16,  8, 15, 14,  6, 12,  3,  5, 10,  5,\n",
            "         6,  9, 16,  7,  1, 11,  0, 18, 18, 10, 11,  2, 16,  9,  9,  0,  3, 13,\n",
            "        12,  5,  6,  5,  1,  5, 12, 12,  7, 14, 15,  8, 19, 19, 13,  5,  1, 12,\n",
            "         5, 15,  6,  6,  3,  0,  7, 18, 11,  3, 11, 15, 13, 17,  8, 15,  8, 13,\n",
            "         5,  7,  4,  6, 17,  5, 13,  2,  0, 15,  0, 13,  4, 19, 10, 17, 10, 18,\n",
            "         2,  7, 11,  6, 11, 13, 12, 12, 14,  4,  5, 14,  5,  9,  1,  6, 14, 12,\n",
            "         7, 19,  3, 17,  4,  0,  2, 14,  5, 12, 16,  8,  2,  0,  7, 15, 15, 15,\n",
            "         4, 12, 15,  9,  8,  6,  1, 19, 10,  7, 18,  9, 13,  8, 14,  0,  0, 12,\n",
            "        16,  2,  0, 16, 18, 15, 14, 11, 19,  6, 10,  9, 15, 15, 15, 10, 17, 14,\n",
            "         5,  0, 11, 10, 12, 13,  6,  3,  1,  1, 12,  8,  9,  4,  4,  4, 13,  0,\n",
            "        13,  3,  4, 18])\n",
            "Epoch [1/3], Step [1/32], Loss: 3.0113\n",
            "Accuracy of the network on test set: 21.73% (21.73%)\n",
            "Epoch [2/3], Step [1/32], Loss: 2.8692\n",
            "Epoch [3/3], Step [1/32], Loss: 2.6784\n",
            "35.91429648400003\n",
            "Accuracy of the network on test set: 44.30% (44.30%)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/2 #dt = 125_000\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_1(neurons_in=512, neurons_h1=256, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "import time\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjsTNqwRH5hA",
        "outputId": "c4e0b1f0-dc48-40a0-b3c0-dcca71dfa1db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 256, 1, 512]) torch.Size([256]) tensor([19,  0,  9, 14, 12, 12,  8, 12, 16,  4, 13,  7,  3,  3,  0, 16,  3, 11,\n",
            "         7,  5, 17, 18,  7,  4,  3,  1,  4, 15,  3,  7,  8, 18, 16, 10,  4, 10,\n",
            "        14, 18, 14, 17,  1,  0, 17,  2, 17, 14, 10,  1, 16,  7,  4,  4,  3,  1,\n",
            "        15,  3, 18,  8, 10, 12, 14,  6,  4,  6,  6,  3, 10, 17, 17,  6, 11, 17,\n",
            "         3,  3, 12,  8,  9,  6, 19,  2,  1, 11,  5, 15, 18,  1, 16, 17, 10, 15,\n",
            "        15,  8, 10, 17,  5,  0,  2, 13, 15, 15,  1,  3, 15,  2,  9, 11, 13, 12,\n",
            "        16, 15,  1,  9,  5,  1,  6,  8, 19, 11,  1, 14,  6,  7,  4, 14,  8, 16,\n",
            "         5, 19, 13,  6, 11, 11, 14, 19, 15, 12, 10,  8,  2,  8,  3,  4,  5,  8,\n",
            "        10,  9, 11, 14,  2,  0, 17,  9, 11, 10, 13, 13, 18,  9, 15,  7, 12, 12,\n",
            "         9,  5,  2, 15,  8, 13,  6,  0,  7,  0,  9,  3, 15, 11,  1,  4,  4,  9,\n",
            "        10, 15, 17,  5,  5,  7, 13,  9, 19,  0, 15, 14, 16,  6, 19,  0, 19, 10,\n",
            "        10,  9,  3,  8,  1, 15, 14, 12, 13, 17, 16, 17, 10,  1,  1, 13,  4,  8,\n",
            "         5,  3, 18, 14,  4,  1,  8, 11, 15, 12, 11, 10, 19, 10, 16, 12, 14, 11,\n",
            "        17,  3,  6, 11, 12, 19,  0,  3, 18,  2, 15, 12, 12, 19, 19, 12,  4,  7,\n",
            "        13,  9,  6,  6])\n",
            "Epoch [1/3], Step [1/32], Loss: 3.0058\n",
            "Accuracy of the network on test set: 25.49% (25.49%)\n",
            "Epoch [2/3], Step [1/32], Loss: 2.9195\n",
            "Epoch [3/3], Step [1/32], Loss: 2.8245\n",
            "44.571593310000026\n",
            "Accuracy of the network on test set: 34.54% (34.54%)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/4 #dt = 125_000\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_1(neurons_in=512, neurons_h1=256, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "import time\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6GAuSvzLe98"
      },
      "source": [
        "Deeper networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eiDBJ9xH5e5",
        "outputId": "722fa41c-9067-4115-dd22-009c21cc7972"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256, 1, 512]) torch.Size([256]) tensor([17,  0, 16,  9,  3,  9,  9,  4,  2, 12,  3, 14,  8, 18,  9, 14,  4,  9,\n",
            "        17,  5,  9, 19,  6,  9,  7, 16, 11,  1, 18,  1, 19,  9,  0, 15, 13, 18,\n",
            "         6, 11, 16, 11,  6, 16,  8, 10,  0, 18, 18, 15,  7, 12,  6,  6, 16,  3,\n",
            "        18, 18,  2,  0,  5,  5,  3, 12,  3,  4,  2,  9,  9, 12,  9, 13,  7, 15,\n",
            "         3, 10,  4,  9, 16, 17, 15,  4,  3, 15,  4,  3, 15, 15,  1,  4, 12, 11,\n",
            "         0, 15, 17,  2,  8,  8,  8, 19,  8, 13, 16,  5,  1, 12,  5,  9, 12, 10,\n",
            "        13,  2,  2,  7, 10, 16,  7, 19,  1, 18,  7, 16,  0, 14, 18,  9,  0,  3,\n",
            "        16, 11, 16,  9,  6, 17,  0, 10,  9,  6, 14,  3,  8,  6,  6,  5,  5,  9,\n",
            "        19,  8, 19, 17, 18, 15,  5, 13,  7, 16, 14,  5,  4,  1,  2,  7,  0,  4,\n",
            "        15,  2,  7,  5,  0, 12,  3,  2, 15,  3,  3,  1, 12,  5,  4, 18,  0, 14,\n",
            "        15, 11, 19, 19,  2, 15,  6,  6,  4, 15, 15, 17,  6, 12, 13, 12, 11, 13,\n",
            "        16, 15,  0,  1, 19,  4,  5, 15,  4, 16,  7, 18, 17,  6, 12,  1,  3, 16,\n",
            "        18, 10, 10, 16, 13, 10,  7,  8, 11,  4, 18, 11, 19, 10,  8,  9, 10, 13,\n",
            "        18, 13, 12,  0,  0,  0, 14,  5, 13, 15,  9, 14,  2,  1,  9,  4, 16,  8,\n",
            "         5, 11,  3, 16])\n",
            "Epoch [1/3], Step [1/32], Loss: 2.9976\n",
            "Accuracy of the network on test set: 20.67% (20.67%)\n",
            "Epoch [2/3], Step [1/32], Loss: 2.8344\n",
            "Epoch [3/3], Step [1/32], Loss: 2.6381\n",
            "Training time: 41.0964724760006\n",
            "41.098156640000525\n",
            "Accuracy of the network on test set: 38.96% (38.96%)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/2 #dt = 125_000\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_3(neurons_in=512, neurons_h1=256, neurons_h2=256, neurons_h3=256, dropout=0.5, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "import time\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca5suttjLc32",
        "outputId": "13c44d58-5dcd-463d-b0ec-e50276bcf8b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256, 1, 512]) torch.Size([256]) tensor([11, 17, 16,  8, 19,  5, 14,  5, 14, 17, 13,  2, 18,  1, 14,  9, 19,  2,\n",
            "         2, 14, 14, 14,  3, 13, 18, 13,  3,  0,  8, 13,  3, 16, 10,  6,  8, 16,\n",
            "        13,  9,  4, 12, 13,  1, 16, 14, 13, 16, 16, 13, 17,  0, 11,  3, 19, 19,\n",
            "        13,  7, 19, 18,  5,  0,  8, 12, 15, 10,  2,  7,  2, 19, 13, 15, 12,  4,\n",
            "         8,  6, 11,  8,  6,  6,  0,  6, 16,  0, 16,  8,  9, 16,  8, 16,  5,  7,\n",
            "         5,  0,  4, 12,  6,  8, 17, 13, 15,  5,  8,  6, 19,  2,  7, 15,  1,  8,\n",
            "         9, 10,  5, 13, 11, 11,  6, 15, 19,  2, 18, 15, 19, 12, 12, 14,  9,  6,\n",
            "        14, 11, 11, 12, 18, 15, 18, 18,  4, 13, 16,  6, 12,  0, 12, 14, 17,  9,\n",
            "        12,  9, 16,  9, 17,  3,  0, 16, 15, 19,  2,  6, 15, 11,  4, 18,  4, 18,\n",
            "        11,  2,  0,  6,  7, 18,  8,  2, 12,  0, 13,  8, 13,  1, 15, 10,  4,  0,\n",
            "        10, 12,  5,  4, 16,  9,  9,  1, 15, 17,  8, 17, 11, 14, 15,  4, 14, 11,\n",
            "        11, 12,  7, 15,  9, 18,  0,  7,  4,  9,  4,  2,  4,  8, 10, 14,  2, 15,\n",
            "        13, 11, 18,  3,  1,  6,  6, 14, 15, 19,  4,  4,  8, 13,  6,  1,  4,  7,\n",
            "         8, 12, 13, 17, 17, 15,  3, 13, 19, 12, 15,  7, 19,  9,  4, 11,  9, 17,\n",
            "         7, 19,  3,  8])\n",
            "Epoch [1/3], Step [1/32], Loss: 2.9971\n",
            "Accuracy of the network on test set: 15.33% (15.33%)\n",
            "Epoch [2/3], Step [1/32], Loss: 2.8332\n",
            "Epoch [3/3], Step [1/32], Loss: 2.6066\n",
            "43.70878852199996\n",
            "Accuracy of the network on test set: 28.27% (28.27%)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/2 #dt = 125_000\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_4(neurons_in=512, neurons_h1=256, neurons_h2=256, neurons_h3=256, neurons_h4=256, dropout=0.5, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN6QNUxdH5c0",
        "outputId": "00adc24d-d23c-4128-e943-cd1803605bc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([32, 256, 1, 512]) torch.Size([256]) tensor([18, 15, 13, 15, 10,  9,  2,  5, 16, 17,  3,  6, 19, 12, 13, 17, 14, 19,\n",
            "        14, 18, 16,  5, 14, 13, 12,  5, 18,  2, 19,  4,  5,  9, 14,  2,  7, 10,\n",
            "        10,  9, 14,  3,  7, 19,  6,  6, 14, 10, 18, 14,  8, 15, 19, 11,  5, 13,\n",
            "         5, 15,  5,  6, 18,  6, 17, 13,  1,  4,  0,  2,  2, 10, 16, 12, 15, 11,\n",
            "         0,  5, 12, 16,  1,  2,  2,  1, 14,  9,  3, 11, 15,  5,  3, 16, 12, 13,\n",
            "        11,  9,  4, 18,  1, 16,  5,  8,  8,  6,  6, 14, 14, 12,  2,  4, 19, 10,\n",
            "         4,  6,  7,  8, 10,  9, 12, 11, 18, 11, 19, 18,  7, 19, 17, 13, 17, 11,\n",
            "         6,  6, 11, 16, 14, 16, 10,  9,  1, 12, 17, 16, 13, 19,  4, 13, 10, 13,\n",
            "        19, 11, 12,  9,  2, 10, 16,  7,  4, 16, 15,  5, 15, 13,  8, 16,  6, 12,\n",
            "         6,  9, 11,  6, 19, 16,  9, 18, 10, 11, 13, 14, 11,  0, 18,  8,  4, 16,\n",
            "         0, 12, 14,  3, 16,  9,  5,  7,  7, 13, 11,  2, 16,  3,  2,  5,  5, 18,\n",
            "         5, 13, 13,  0, 12, 15, 15, 13,  1, 10,  2, 19,  5,  8,  8,  2,  1, 11,\n",
            "         2, 16,  6,  4, 18, 16, 19, 17,  1,  2, 14, 19,  9,  6,  2, 18,  8, 18,\n",
            "         9,  6,  1, 17, 16,  5, 14, 11,  3,  2,  6, 18, 18, 12,  6, 14,  2,  7,\n",
            "        15, 15, 19,  4])\n",
            "Epoch [1/3], Step [1/32], Loss: 3.0283\n",
            "Accuracy of the network on test set: 9.76% (9.76%)\n",
            "Epoch [2/3], Step [1/32], Loss: 2.6906\n",
            "Epoch [3/3], Step [1/32], Loss: 2.5910\n",
            "47.14713932199993\n",
            "Accuracy of the network on test set: 17.58% (17.58%)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/2 #dt = 125_000\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 3\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_4(neurons_in=512, neurons_h1=256, neurons_h2=256, neurons_h3=256, neurons_h4=256, dropout=0.5, bn=True).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "import time\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOJqqSgmH5ad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYWHSwhIM4nB",
        "outputId": "632957c2-20ab-4204-a7d5-768619530052"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 256, 1, 512]) torch.Size([256]) tensor([ 7,  9,  5, 10,  0,  2, 11, 12,  9,  2,  3, 13,  8, 12,  5, 12, 16, 16,\n",
            "        19, 16, 16,  4,  2,  8,  0, 14, 18, 10,  7,  0, 14,  7, 11, 19,  8,  8,\n",
            "        17, 18, 10, 13, 10, 18, 18,  8, 14,  0, 11,  3,  2,  8, 19,  2, 12,  0,\n",
            "         2,  1,  2, 17,  4,  5,  5,  1,  7,  7,  4,  7,  1, 18, 10,  1,  9, 17,\n",
            "        11,  1,  8,  7, 11, 13,  5, 17, 13, 13, 14,  0,  2,  8,  5, 10,  4, 12,\n",
            "        11, 17, 14, 13, 15,  4, 16,  4, 13, 19, 11,  7, 16, 19, 12, 14, 16,  6,\n",
            "         7,  5, 10, 10,  7,  4, 11, 14, 17,  7,  3,  2, 18,  5, 13,  8,  6,  1,\n",
            "         2, 17, 14, 11,  4,  1, 19, 10, 19,  0, 14,  0, 17,  9,  0, 10,  6,  3,\n",
            "        14, 15,  6, 18, 12,  9,  1, 13, 10, 18,  7,  3, 17,  1,  1,  1, 17, 17,\n",
            "        12,  4,  9, 12,  0,  8,  2,  7, 16,  0,  9,  1,  3,  6,  4, 19, 15, 18,\n",
            "         3, 17,  7, 15, 18,  0,  5,  0, 16,  1,  6, 17, 19, 17,  0,  2, 19, 18,\n",
            "        16,  6,  9, 16, 15, 15,  2,  8,  0,  9,  1, 11, 17, 13, 16,  3, 18, 17,\n",
            "        16,  0,  5,  5, 15,  4,  1, 11, 10,  3,  4, 14,  9,  6, 19,  8, 13, 15,\n",
            "         6,  5,  1, 11, 16,  4, 17, 10,  8,  5,  5,  4, 15,  2,  1, 19,  9,  6,\n",
            "        17,  2, 11, 17])\n",
            "Epoch [1/100], Step [1/32], Loss: 2.9976\n",
            "Accuracy of the network on test set: 13.25% (13.25%)\n",
            "Epoch [2/100], Step [1/32], Loss: 2.8239\n",
            "Epoch [3/100], Step [1/32], Loss: 2.6686\n",
            "Epoch [4/100], Step [1/32], Loss: 2.6483\n",
            "Epoch [5/100], Step [1/32], Loss: 2.6114\n",
            "Epoch [6/100], Step [1/32], Loss: 2.5835\n",
            "Epoch [7/100], Step [1/32], Loss: 2.5891\n",
            "Epoch [8/100], Step [1/32], Loss: 2.5654\n",
            "Epoch [9/100], Step [1/32], Loss: 2.5682\n",
            "Epoch [10/100], Step [1/32], Loss: 2.5458\n",
            "Epoch [11/100], Step [1/32], Loss: 2.5448\n",
            "Accuracy of the network on test set: 42.93% (42.93%)\n",
            "Epoch [12/100], Step [1/32], Loss: 2.5215\n",
            "Epoch [13/100], Step [1/32], Loss: 2.5030\n",
            "Epoch [14/100], Step [1/32], Loss: 2.4808\n",
            "Epoch [15/100], Step [1/32], Loss: 2.4626\n",
            "Epoch [16/100], Step [1/32], Loss: 2.4713\n",
            "Epoch [17/100], Step [1/32], Loss: 2.5017\n",
            "Epoch [18/100], Step [1/32], Loss: 2.5002\n",
            "Epoch [19/100], Step [1/32], Loss: 2.4671\n",
            "Epoch [20/100], Step [1/32], Loss: 2.4419\n",
            "Epoch [21/100], Step [1/32], Loss: 2.4562\n",
            "Accuracy of the network on test set: 55.92% (55.92%)\n",
            "Epoch [22/100], Step [1/32], Loss: 2.4637\n",
            "Epoch [23/100], Step [1/32], Loss: 2.4487\n",
            "Epoch [24/100], Step [1/32], Loss: 2.4362\n",
            "Epoch [25/100], Step [1/32], Loss: 2.4312\n",
            "Epoch [26/100], Step [1/32], Loss: 2.4478\n",
            "Epoch [27/100], Step [1/32], Loss: 2.4149\n",
            "Epoch [28/100], Step [1/32], Loss: 2.4208\n",
            "Epoch [29/100], Step [1/32], Loss: 2.4307\n",
            "Epoch [30/100], Step [1/32], Loss: 2.4154\n",
            "Epoch [31/100], Step [1/32], Loss: 2.4428\n",
            "Accuracy of the network on test set: 58.75% (58.75%)\n",
            "Epoch [32/100], Step [1/32], Loss: 2.4135\n",
            "Epoch [33/100], Step [1/32], Loss: 2.4124\n",
            "Epoch [34/100], Step [1/32], Loss: 2.3942\n",
            "Epoch [35/100], Step [1/32], Loss: 2.4012\n",
            "Epoch [36/100], Step [1/32], Loss: 2.4396\n",
            "Epoch [37/100], Step [1/32], Loss: 2.3834\n",
            "Epoch [38/100], Step [1/32], Loss: 2.3853\n",
            "Epoch [39/100], Step [1/32], Loss: 2.3801\n",
            "Epoch [40/100], Step [1/32], Loss: 2.3893\n",
            "Epoch [41/100], Step [1/32], Loss: 2.3897\n",
            "Accuracy of the network on test set: 56.32% (56.32%)\n",
            "Epoch [42/100], Step [1/32], Loss: 2.3774\n",
            "Epoch [43/100], Step [1/32], Loss: 2.3759\n",
            "Epoch [44/100], Step [1/32], Loss: 2.3870\n",
            "Epoch [45/100], Step [1/32], Loss: 2.3759\n",
            "Epoch [46/100], Step [1/32], Loss: 2.3765\n",
            "Epoch [47/100], Step [1/32], Loss: 2.3761\n",
            "Epoch [48/100], Step [1/32], Loss: 2.3715\n",
            "Epoch [49/100], Step [1/32], Loss: 2.3871\n",
            "Epoch [50/100], Step [1/32], Loss: 2.3724\n",
            "Epoch [51/100], Step [1/32], Loss: 2.3770\n",
            "Accuracy of the network on test set: 60.60% (60.60%)\n",
            "Epoch [52/100], Step [1/32], Loss: 2.3758\n",
            "Epoch [53/100], Step [1/32], Loss: 2.3731\n",
            "Epoch [54/100], Step [1/32], Loss: 2.3703\n",
            "Epoch [55/100], Step [1/32], Loss: 2.3593\n",
            "Epoch [56/100], Step [1/32], Loss: 2.3748\n",
            "Epoch [57/100], Step [1/32], Loss: 2.3749\n",
            "Epoch [58/100], Step [1/32], Loss: 2.3526\n",
            "Epoch [59/100], Step [1/32], Loss: 2.3620\n",
            "Epoch [60/100], Step [1/32], Loss: 2.3551\n",
            "Epoch [61/100], Step [1/32], Loss: 2.3604\n",
            "Accuracy of the network on test set: 62.81% (62.81%)\n",
            "Epoch [62/100], Step [1/32], Loss: 2.3476\n",
            "Epoch [63/100], Step [1/32], Loss: 2.3488\n",
            "Epoch [64/100], Step [1/32], Loss: 2.3555\n",
            "Epoch [65/100], Step [1/32], Loss: 2.3368\n",
            "Epoch [66/100], Step [1/32], Loss: 2.3565\n",
            "Epoch [67/100], Step [1/32], Loss: 2.3415\n",
            "Epoch [68/100], Step [1/32], Loss: 2.3603\n",
            "Epoch [69/100], Step [1/32], Loss: 2.3601\n",
            "Epoch [70/100], Step [1/32], Loss: 2.3592\n",
            "Epoch [71/100], Step [1/32], Loss: 2.3560\n",
            "Accuracy of the network on test set: 63.91% (63.91%)\n",
            "Epoch [72/100], Step [1/32], Loss: 2.3581\n",
            "Epoch [73/100], Step [1/32], Loss: 2.3331\n",
            "Epoch [74/100], Step [1/32], Loss: 2.3377\n",
            "Epoch [75/100], Step [1/32], Loss: 2.3551\n",
            "Epoch [76/100], Step [1/32], Loss: 2.3557\n",
            "Epoch [77/100], Step [1/32], Loss: 2.3579\n",
            "Epoch [78/100], Step [1/32], Loss: 2.3420\n",
            "Epoch [79/100], Step [1/32], Loss: 2.3607\n",
            "Epoch [80/100], Step [1/32], Loss: 2.3653\n",
            "Epoch [81/100], Step [1/32], Loss: 2.3324\n",
            "Accuracy of the network on test set: 63.91% (63.91%)\n",
            "Epoch [82/100], Step [1/32], Loss: 2.3449\n",
            "Epoch [83/100], Step [1/32], Loss: 2.3517\n",
            "Epoch [84/100], Step [1/32], Loss: 2.3551\n",
            "Epoch [85/100], Step [1/32], Loss: 2.3441\n",
            "Epoch [86/100], Step [1/32], Loss: 2.3581\n",
            "Epoch [87/100], Step [1/32], Loss: 2.3363\n",
            "Epoch [88/100], Step [1/32], Loss: 2.3419\n",
            "Epoch [89/100], Step [1/32], Loss: 2.3251\n",
            "Epoch [90/100], Step [1/32], Loss: 2.3433\n",
            "Epoch [91/100], Step [1/32], Loss: 2.3280\n",
            "Accuracy of the network on test set: 67.09% (67.09%)\n",
            "Epoch [92/100], Step [1/32], Loss: 2.3307\n",
            "Epoch [93/100], Step [1/32], Loss: 2.3279\n",
            "Epoch [94/100], Step [1/32], Loss: 2.3348\n",
            "Epoch [95/100], Step [1/32], Loss: 2.3190\n",
            "Epoch [96/100], Step [1/32], Loss: 2.3236\n",
            "Epoch [97/100], Step [1/32], Loss: 2.3395\n",
            "Epoch [98/100], Step [1/32], Loss: 2.3500\n",
            "Epoch [99/100], Step [1/32], Loss: 2.3352\n",
            "Epoch [100/100], Step [1/32], Loss: 2.3294\n",
            "1983.482278243\n",
            "Accuracy of the network on test set: 66.03% (66.03%)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/4 #dt = 125_000\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 200 # 67% after 100, 69% after 200\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_4(neurons_in=512, neurons_h1=256, neurons_h2=256, neurons_h3=256, neurons_h4=256, dropout=0.5, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "import time\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7zguzvZMJwN",
        "outputId": "24a87367-4054-450f-c8f7-3c92c9c0ea19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 4096, 1, 512]) torch.Size([4096]) tensor([13, 14, 18,  ..., 16, 10,  8])\n",
            "Epoch [1/30], Step [1/2], Loss: 2.3181\n",
            "Accuracy of the network on test set: 68.11% (68.11%)\n",
            "Epoch [2/30], Step [1/2], Loss: 2.3280\n",
            "Epoch [3/30], Step [1/2], Loss: 2.3300\n",
            "Epoch [4/30], Step [1/2], Loss: 2.3263\n",
            "Epoch [5/30], Step [1/2], Loss: 2.3273\n",
            "Epoch [6/30], Step [1/2], Loss: 2.3242\n",
            "Epoch [7/30], Step [1/2], Loss: 2.3199\n",
            "Epoch [8/30], Step [1/2], Loss: 2.3223\n",
            "Epoch [9/30], Step [1/2], Loss: 2.3196\n",
            "Epoch [10/30], Step [1/2], Loss: 2.3221\n",
            "Epoch [11/30], Step [1/2], Loss: 2.3213\n",
            "Accuracy of the network on test set: 69.13% (69.13%)\n",
            "Epoch [12/30], Step [1/2], Loss: 2.3165\n",
            "Epoch [13/30], Step [1/2], Loss: 2.3161\n",
            "Epoch [14/30], Step [1/2], Loss: 2.3178\n",
            "Epoch [15/30], Step [1/2], Loss: 2.3192\n",
            "Epoch [16/30], Step [1/2], Loss: 2.3154\n",
            "Epoch [17/30], Step [1/2], Loss: 2.3148\n",
            "Epoch [18/30], Step [1/2], Loss: 2.3105\n",
            "Epoch [19/30], Step [1/2], Loss: 2.3126\n",
            "Epoch [20/30], Step [1/2], Loss: 2.3121\n",
            "Epoch [21/30], Step [1/2], Loss: 2.3116\n",
            "Accuracy of the network on test set: 68.51% (68.51%)\n",
            "Epoch [22/30], Step [1/2], Loss: 2.3146\n",
            "Epoch [23/30], Step [1/2], Loss: 2.3143\n",
            "Epoch [24/30], Step [1/2], Loss: 2.3163\n",
            "Epoch [25/30], Step [1/2], Loss: 2.3139\n",
            "Epoch [26/30], Step [1/2], Loss: 2.3129\n",
            "Epoch [27/30], Step [1/2], Loss: 2.3115\n",
            "Epoch [28/30], Step [1/2], Loss: 2.3152\n",
            "Epoch [29/30], Step [1/2], Loss: 2.3143\n",
            "Epoch [30/30], Step [1/2], Loss: 2.3137\n",
            "336.6380563140001\n",
            "Accuracy of the network on test set: 68.02% (68.02%)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 4096\n",
        "\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.0005\n",
        "num_epochs = 30\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfvR9I8ItCtn",
        "outputId": "197bbc03-8ffe-4585-9ecb-caafd3c33bad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/30], Step [1/2], Loss: 2.3121\n",
            "Accuracy of the network on test set: 69.26% (69.26%)\n",
            "Epoch [2/30], Step [1/2], Loss: 2.3119\n",
            "Epoch [3/30], Step [1/2], Loss: 2.3141\n",
            "Epoch [4/30], Step [1/2], Loss: 2.3163\n",
            "Epoch [5/30], Step [1/2], Loss: 2.3135\n",
            "Epoch [6/30], Step [1/2], Loss: 2.3152\n",
            "Epoch [7/30], Step [1/2], Loss: 2.3129\n",
            "Epoch [8/30], Step [1/2], Loss: 2.3147\n",
            "Epoch [9/30], Step [1/2], Loss: 2.3137\n",
            "Epoch [10/30], Step [1/2], Loss: 2.3107\n",
            "Epoch [11/30], Step [1/2], Loss: 2.3122\n",
            "Accuracy of the network on test set: 69.17% (69.17%)\n",
            "Epoch [12/30], Step [1/2], Loss: 2.3130\n",
            "Epoch [13/30], Step [1/2], Loss: 2.3108\n",
            "Epoch [14/30], Step [1/2], Loss: 2.3130\n",
            "Epoch [15/30], Step [1/2], Loss: 2.3119\n",
            "Epoch [16/30], Step [1/2], Loss: 2.3112\n",
            "Epoch [17/30], Step [1/2], Loss: 2.3132\n",
            "Epoch [18/30], Step [1/2], Loss: 2.3141\n",
            "Epoch [19/30], Step [1/2], Loss: 2.3100\n",
            "Epoch [20/30], Step [1/2], Loss: 2.3129\n",
            "Epoch [21/30], Step [1/2], Loss: 2.3139\n",
            "Accuracy of the network on test set: 68.82% (68.82%)\n",
            "Epoch [22/30], Step [1/2], Loss: 2.3099\n",
            "Epoch [23/30], Step [1/2], Loss: 2.3130\n",
            "Epoch [24/30], Step [1/2], Loss: 2.3104\n",
            "Epoch [25/30], Step [1/2], Loss: 2.3122\n",
            "Epoch [26/30], Step [1/2], Loss: 2.3108\n",
            "Epoch [27/30], Step [1/2], Loss: 2.3138\n",
            "Epoch [28/30], Step [1/2], Loss: 2.3120\n",
            "Epoch [29/30], Step [1/2], Loss: 2.3112\n",
            "Epoch [30/30], Step [1/2], Loss: 2.3127\n",
            "Training time: 336.70258317800017\n",
            "Accuracy of the network on test set: 68.51% (68.51%)\n"
          ]
        }
      ],
      "source": [
        "learning_rate = 0.0001\n",
        "num_epochs = 30\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader)\n",
        "accuracy(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHLipGfI4qH5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNC9mUmY4p4f",
        "outputId": "7ee98224-6c5e-476e-e6b9-35aa44cb7081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on test set: 68.51% (68.51%)\n",
            "Accuracy of the network on 2 classes: 81.54%\n"
          ]
        }
      ],
      "source": [
        "accuracy(model, testloader, device)\n",
        "accuracy_2class(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kC1MSaqX4lP1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mgpfl4cPIRfv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DotbIc2YIRWT",
        "outputId": "67557b65-bfcc-48dd-cc03-0fc0a2c865ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 256, 1, 512]) torch.Size([256]) tensor([ 8, 14,  0, 15,  0, 12, 12, 10,  1, 19, 12,  6,  3,  9,  0,  5, 15, 13,\n",
            "        11,  5, 13, 10, 12, 12, 14,  7, 14,  0,  0,  7, 16,  7,  5,  1, 17, 17,\n",
            "         8, 11, 14,  1,  6, 15, 10,  7, 11, 18,  4,  5,  7,  0, 19, 18,  0, 19,\n",
            "        10, 18,  6,  8, 13, 11, 13,  5,  1,  8, 11, 10, 17, 11,  2,  1,  8, 14,\n",
            "        19, 18, 18, 19, 18,  9, 18,  9, 14, 13,  0,  3, 18,  3, 14, 14,  0, 13,\n",
            "         0, 13,  4, 13, 16, 13,  7, 14,  8,  6, 16, 18, 14,  5,  6, 17, 11, 16,\n",
            "        11,  0, 10, 18, 12, 12,  6,  7,  6,  4,  2, 10, 13,  6, 14, 18, 16, 15,\n",
            "        19,  7,  6, 15, 11,  1,  5,  5, 17, 16, 15, 18, 19,  0, 17, 19,  7, 14,\n",
            "         1,  9,  9, 18, 13, 14, 13,  8, 11,  7,  3,  5, 14,  9,  9, 15,  8,  2,\n",
            "         7,  9, 17,  2, 15,  0, 15, 18, 17,  9,  9, 13,  2,  0,  5,  4,  5,  3,\n",
            "         4,  0,  0, 10,  3,  5, 12, 12, 19, 19, 18,  0,  1, 18,  1,  1,  8,  6,\n",
            "         6, 17, 11, 18, 17,  2,  5,  7,  1, 17,  1,  6,  3,  4,  7, 10,  4,  3,\n",
            "         3, 16,  6,  7,  7,  8,  3,  6,  4,  5, 18,  9, 19, 15,  6, 12, 10,  1,\n",
            "        12,  2, 14,  7, 15, 14, 14, 13,  1,  9,  3, 13,  0,  4,  0, 17,  8,  2,\n",
            "         0, 15, 10, 14])\n",
            "Epoch [1/150], Step [1/32], Loss: 3.0002\n",
            "Accuracy of the network on test set: 19.52% (19.52%)\n",
            "Epoch [2/150], Step [1/32], Loss: 2.9169\n",
            "Epoch [3/150], Step [1/32], Loss: 2.7571\n",
            "Epoch [4/150], Step [1/32], Loss: 2.6608\n",
            "Epoch [5/150], Step [1/32], Loss: 2.6202\n",
            "Epoch [6/150], Step [1/32], Loss: 2.5803\n",
            "Epoch [7/150], Step [1/32], Loss: 2.5454\n",
            "Epoch [8/150], Step [1/32], Loss: 2.5359\n",
            "Epoch [9/150], Step [1/32], Loss: 2.5335\n",
            "Epoch [10/150], Step [1/32], Loss: 2.5113\n",
            "Epoch [11/150], Step [1/32], Loss: 2.4991\n",
            "Accuracy of the network on test set: 57.69% (57.69%)\n",
            "Epoch [12/150], Step [1/32], Loss: 2.4920\n",
            "Epoch [13/150], Step [1/32], Loss: 2.4977\n",
            "Epoch [14/150], Step [1/32], Loss: 2.4683\n",
            "Epoch [15/150], Step [1/32], Loss: 2.4567\n",
            "Epoch [16/150], Step [1/32], Loss: 2.4536\n",
            "Epoch [17/150], Step [1/32], Loss: 2.4440\n",
            "Epoch [18/150], Step [1/32], Loss: 2.4466\n",
            "Epoch [19/150], Step [1/32], Loss: 2.4294\n",
            "Epoch [20/150], Step [1/32], Loss: 2.4448\n",
            "Epoch [21/150], Step [1/32], Loss: 2.4217\n",
            "Accuracy of the network on test set: 65.77% (65.77%)\n",
            "Epoch [22/150], Step [1/32], Loss: 2.4065\n",
            "Epoch [23/150], Step [1/32], Loss: 2.4302\n",
            "Epoch [24/150], Step [1/32], Loss: 2.4079\n",
            "Epoch [25/150], Step [1/32], Loss: 2.3966\n",
            "Epoch [26/150], Step [1/32], Loss: 2.3892\n",
            "Epoch [27/150], Step [1/32], Loss: 2.3776\n",
            "Epoch [28/150], Step [1/32], Loss: 2.3876\n",
            "Epoch [29/150], Step [1/32], Loss: 2.3927\n",
            "Epoch [30/150], Step [1/32], Loss: 2.3936\n",
            "Epoch [31/150], Step [1/32], Loss: 2.3570\n",
            "Accuracy of the network on test set: 66.56% (66.56%)\n",
            "Epoch [32/150], Step [1/32], Loss: 2.3698\n",
            "Epoch [33/150], Step [1/32], Loss: 2.3765\n",
            "Epoch [34/150], Step [1/32], Loss: 2.3603\n",
            "Epoch [35/150], Step [1/32], Loss: 2.3626\n",
            "Epoch [36/150], Step [1/32], Loss: 2.3455\n",
            "Epoch [37/150], Step [1/32], Loss: 2.3483\n",
            "Epoch [38/150], Step [1/32], Loss: 2.3609\n",
            "Epoch [39/150], Step [1/32], Loss: 2.3400\n",
            "Epoch [40/150], Step [1/32], Loss: 2.3474\n",
            "Epoch [41/150], Step [1/32], Loss: 2.3554\n",
            "Accuracy of the network on test set: 68.07% (68.07%)\n",
            "Epoch [42/150], Step [1/32], Loss: 2.3549\n",
            "Epoch [43/150], Step [1/32], Loss: 2.3206\n",
            "Epoch [44/150], Step [1/32], Loss: 2.3533\n",
            "Epoch [45/150], Step [1/32], Loss: 2.3449\n",
            "Epoch [46/150], Step [1/32], Loss: 2.3308\n",
            "Epoch [47/150], Step [1/32], Loss: 2.3242\n",
            "Epoch [48/150], Step [1/32], Loss: 2.3372\n",
            "Epoch [49/150], Step [1/32], Loss: 2.3272\n",
            "Epoch [50/150], Step [1/32], Loss: 2.3309\n",
            "Epoch [51/150], Step [1/32], Loss: 2.3367\n",
            "Accuracy of the network on test set: 68.46% (68.46%)\n",
            "Epoch [52/150], Step [1/32], Loss: 2.3193\n",
            "Epoch [53/150], Step [1/32], Loss: 2.3184\n",
            "Epoch [54/150], Step [1/32], Loss: 2.3092\n",
            "Epoch [55/150], Step [1/32], Loss: 2.3154\n",
            "Epoch [56/150], Step [1/32], Loss: 2.3169\n",
            "Epoch [57/150], Step [1/32], Loss: 2.3203\n",
            "Epoch [58/150], Step [1/32], Loss: 2.3062\n",
            "Epoch [59/150], Step [1/32], Loss: 2.3173\n",
            "Epoch [60/150], Step [1/32], Loss: 2.3079\n",
            "Epoch [61/150], Step [1/32], Loss: 2.2983\n",
            "Accuracy of the network on test set: 70.23% (70.23%)\n",
            "Epoch [62/150], Step [1/32], Loss: 2.2981\n",
            "Epoch [63/150], Step [1/32], Loss: 2.3057\n",
            "Epoch [64/150], Step [1/32], Loss: 2.3068\n",
            "Epoch [65/150], Step [1/32], Loss: 2.2991\n",
            "Epoch [66/150], Step [1/32], Loss: 2.2892\n",
            "Epoch [67/150], Step [1/32], Loss: 2.3030\n",
            "Epoch [68/150], Step [1/32], Loss: 2.2843\n",
            "Epoch [69/150], Step [1/32], Loss: 2.2917\n",
            "Epoch [70/150], Step [1/32], Loss: 2.2810\n",
            "Epoch [71/150], Step [1/32], Loss: 2.2914\n",
            "Accuracy of the network on test set: 70.72% (70.72%)\n",
            "Epoch [72/150], Step [1/32], Loss: 2.2917\n",
            "Epoch [73/150], Step [1/32], Loss: 2.2940\n",
            "Epoch [74/150], Step [1/32], Loss: 2.2990\n",
            "Epoch [75/150], Step [1/32], Loss: 2.2937\n",
            "Epoch [76/150], Step [1/32], Loss: 2.2722\n",
            "Epoch [77/150], Step [1/32], Loss: 2.2930\n",
            "Epoch [78/150], Step [1/32], Loss: 2.2754\n",
            "Epoch [79/150], Step [1/32], Loss: 2.2807\n",
            "Epoch [80/150], Step [1/32], Loss: 2.2844\n",
            "Epoch [81/150], Step [1/32], Loss: 2.2827\n",
            "Accuracy of the network on test set: 71.64% (71.64%)\n",
            "Epoch [82/150], Step [1/32], Loss: 2.2838\n",
            "Epoch [83/150], Step [1/32], Loss: 2.2825\n",
            "Epoch [84/150], Step [1/32], Loss: 2.2755\n",
            "Epoch [85/150], Step [1/32], Loss: 2.2747\n",
            "Epoch [86/150], Step [1/32], Loss: 2.2815\n",
            "Epoch [87/150], Step [1/32], Loss: 2.2726\n",
            "Epoch [88/150], Step [1/32], Loss: 2.2757\n",
            "Epoch [89/150], Step [1/32], Loss: 2.2850\n",
            "Epoch [90/150], Step [1/32], Loss: 2.2723\n",
            "Epoch [91/150], Step [1/32], Loss: 2.2819\n",
            "Accuracy of the network on test set: 72.66% (72.66%)\n",
            "Epoch [92/150], Step [1/32], Loss: 2.2849\n",
            "Epoch [93/150], Step [1/32], Loss: 2.2881\n",
            "Epoch [94/150], Step [1/32], Loss: 2.2764\n",
            "Epoch [95/150], Step [1/32], Loss: 2.2838\n",
            "Epoch [96/150], Step [1/32], Loss: 2.2742\n",
            "Epoch [97/150], Step [1/32], Loss: 2.2673\n",
            "Epoch [98/150], Step [1/32], Loss: 2.2795\n",
            "Epoch [99/150], Step [1/32], Loss: 2.2783\n",
            "Epoch [100/150], Step [1/32], Loss: 2.2696\n",
            "Epoch [101/150], Step [1/32], Loss: 2.2861\n",
            "Accuracy of the network on test set: 72.48% (72.48%)\n",
            "Epoch [102/150], Step [1/32], Loss: 2.2747\n",
            "Epoch [103/150], Step [1/32], Loss: 2.2682\n",
            "Epoch [104/150], Step [1/32], Loss: 2.2583\n",
            "Epoch [105/150], Step [1/32], Loss: 2.2768\n",
            "Epoch [106/150], Step [1/32], Loss: 2.2730\n",
            "Epoch [107/150], Step [1/32], Loss: 2.2875\n",
            "Epoch [108/150], Step [1/32], Loss: 2.2817\n",
            "Epoch [109/150], Step [1/32], Loss: 2.2756\n",
            "Epoch [110/150], Step [1/32], Loss: 2.2830\n",
            "Epoch [111/150], Step [1/32], Loss: 2.2758\n",
            "Accuracy of the network on test set: 72.22% (72.22%)\n",
            "Epoch [112/150], Step [1/32], Loss: 2.2699\n",
            "Epoch [113/150], Step [1/32], Loss: 2.2579\n",
            "Epoch [114/150], Step [1/32], Loss: 2.2598\n",
            "Epoch [115/150], Step [1/32], Loss: 2.2675\n",
            "Epoch [116/150], Step [1/32], Loss: 2.2699\n",
            "Epoch [117/150], Step [1/32], Loss: 2.2822\n",
            "Epoch [118/150], Step [1/32], Loss: 2.2750\n",
            "Epoch [119/150], Step [1/32], Loss: 2.2714\n",
            "Epoch [120/150], Step [1/32], Loss: 2.2834\n",
            "Epoch [121/150], Step [1/32], Loss: 2.2740\n",
            "Accuracy of the network on test set: 72.70% (72.70%)\n",
            "Epoch [122/150], Step [1/32], Loss: 2.2656\n",
            "Epoch [123/150], Step [1/32], Loss: 2.2725\n",
            "Epoch [124/150], Step [1/32], Loss: 2.2661\n",
            "Epoch [125/150], Step [1/32], Loss: 2.2599\n",
            "Epoch [126/150], Step [1/32], Loss: 2.2728\n",
            "Epoch [127/150], Step [1/32], Loss: 2.2713\n",
            "Epoch [128/150], Step [1/32], Loss: 2.2675\n",
            "Epoch [129/150], Step [1/32], Loss: 2.2729\n",
            "Epoch [130/150], Step [1/32], Loss: 2.2577\n",
            "Epoch [131/150], Step [1/32], Loss: 2.2685\n",
            "Accuracy of the network on test set: 72.84% (72.84%)\n",
            "Epoch [132/150], Step [1/32], Loss: 2.2646\n",
            "Epoch [133/150], Step [1/32], Loss: 2.2634\n",
            "Epoch [134/150], Step [1/32], Loss: 2.2584\n",
            "Epoch [135/150], Step [1/32], Loss: 2.2600\n",
            "Epoch [136/150], Step [1/32], Loss: 2.2615\n",
            "Epoch [137/150], Step [1/32], Loss: 2.2750\n",
            "Epoch [138/150], Step [1/32], Loss: 2.2688\n",
            "Epoch [139/150], Step [1/32], Loss: 2.2660\n",
            "Epoch [140/150], Step [1/32], Loss: 2.2613\n",
            "Epoch [141/150], Step [1/32], Loss: 2.2622\n",
            "Accuracy of the network on test set: 73.45% (73.45%)\n",
            "Epoch [142/150], Step [1/32], Loss: 2.2751\n",
            "Epoch [143/150], Step [1/32], Loss: 2.2589\n",
            "Epoch [144/150], Step [1/32], Loss: 2.2704\n",
            "Epoch [145/150], Step [1/32], Loss: 2.2542\n",
            "Epoch [146/150], Step [1/32], Loss: 2.2640\n",
            "Epoch [147/150], Step [1/32], Loss: 2.2701\n",
            "Epoch [148/150], Step [1/32], Loss: 2.2652\n",
            "Epoch [149/150], Step [1/32], Loss: 2.2669\n",
            "Epoch [150/150], Step [1/32], Loss: 2.2671\n",
            "Training time: 2323.273502463\n",
            "2323.2756425880007\n",
            "Accuracy of the network on test set: 73.32% (73.32%)\n",
            "Accuracy of the network on 2 classes: 82.20%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/4\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 150\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_2(neurons_in=512, neurons_h1=256, neurons_h2=128, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)\n",
        "accuracy_2class(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxRQIUj4Tf0d",
        "outputId": "63252525-06ca-4a84-8361-d12132210df3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 256, 1, 512]) torch.Size([256]) tensor([ 2, 10, 18,  2, 16,  6,  9, 17, 12, 12, 13, 13,  5,  8, 19, 19,  8,  6,\n",
            "        12,  2, 17,  2, 14,  0,  7,  3, 10,  1,  1, 18, 12,  0, 15,  1,  6, 16,\n",
            "        11,  1, 14, 12,  9, 12, 15,  6,  4,  2,  1,  6,  2, 15, 14, 14,  4,  7,\n",
            "        19,  9, 15,  6, 11,  0, 13, 14, 16, 10,  8,  9, 13, 15, 10, 10,  4, 13,\n",
            "         0,  4,  6, 13,  6, 19, 17,  6,  1, 15, 10,  9,  7, 17, 17,  5,  0,  9,\n",
            "         6, 14, 16, 18, 17,  5,  3,  0,  9, 18,  7,  5, 11,  7, 11,  2, 12,  0,\n",
            "        13,  5, 18,  2, 18,  5, 19,  3,  7,  8, 16,  1,  1,  4, 10,  6,  7, 11,\n",
            "        17, 19, 14, 10,  3,  2,  7,  4,  0,  0, 19, 13, 17, 14,  3, 13, 13,  8,\n",
            "         0, 15,  3,  0, 14,  0,  2,  3,  9,  9, 16,  9,  2,  4, 17,  4,  2,  2,\n",
            "        13,  5,  8,  9, 10,  6, 10,  7, 13, 15,  7,  0, 14,  1,  5, 10, 13, 11,\n",
            "         5,  7,  3, 15, 12, 19, 15, 19, 10,  9, 11,  3, 19, 14,  4, 10,  1, 10,\n",
            "         7,  2,  6,  9, 16, 11, 15, 12, 11,  3, 19,  3, 10, 12, 19,  8, 12,  5,\n",
            "         4,  2, 15,  3,  8,  9,  4,  9,  5,  9,  0, 16, 11, 17, 19,  3,  3,  1,\n",
            "         8,  8, 14, 16,  7,  6, 10, 10,  0, 19, 15,  6, 17, 16,  4,  1, 16, 17,\n",
            "        16, 10,  9, 19])\n",
            "Epoch [1/150], Step [1/32], Loss: 3.0040\n",
            "Accuracy of the network on test set: 21.42% (21.42%)\n",
            "Epoch [2/150], Step [1/32], Loss: 2.9004\n",
            "Epoch [3/150], Step [1/32], Loss: 2.7258\n",
            "Epoch [4/150], Step [1/32], Loss: 2.6644\n",
            "Epoch [5/150], Step [1/32], Loss: 2.6250\n",
            "Epoch [6/150], Step [1/32], Loss: 2.5892\n",
            "Epoch [7/150], Step [1/32], Loss: 2.5939\n",
            "Epoch [8/150], Step [1/32], Loss: 2.5629\n",
            "Epoch [9/150], Step [1/32], Loss: 2.5263\n",
            "Epoch [10/150], Step [1/32], Loss: 2.5170\n",
            "Epoch [11/150], Step [1/32], Loss: 2.5081\n",
            "Accuracy of the network on test set: 48.10% (48.10%)\n",
            "Epoch [12/150], Step [1/32], Loss: 2.5155\n",
            "Epoch [13/150], Step [1/32], Loss: 2.5183\n",
            "Epoch [14/150], Step [1/32], Loss: 2.4994\n",
            "Epoch [15/150], Step [1/32], Loss: 2.4846\n",
            "Epoch [16/150], Step [1/32], Loss: 2.4702\n",
            "Epoch [17/150], Step [1/32], Loss: 2.4720\n",
            "Epoch [18/150], Step [1/32], Loss: 2.4776\n",
            "Epoch [19/150], Step [1/32], Loss: 2.4701\n",
            "Epoch [20/150], Step [1/32], Loss: 2.4475\n",
            "Epoch [21/150], Step [1/32], Loss: 2.4817\n",
            "Accuracy of the network on test set: 59.98% (59.98%)\n",
            "Epoch [22/150], Step [1/32], Loss: 2.4303\n",
            "Epoch [23/150], Step [1/32], Loss: 2.4643\n",
            "Epoch [24/150], Step [1/32], Loss: 2.4430\n",
            "Epoch [25/150], Step [1/32], Loss: 2.4366\n",
            "Epoch [26/150], Step [1/32], Loss: 2.4530\n",
            "Epoch [27/150], Step [1/32], Loss: 2.4224\n",
            "Epoch [28/150], Step [1/32], Loss: 2.4254\n",
            "Epoch [29/150], Step [1/32], Loss: 2.4462\n",
            "Epoch [30/150], Step [1/32], Loss: 2.4290\n",
            "Epoch [31/150], Step [1/32], Loss: 2.4162\n",
            "Accuracy of the network on test set: 61.66% (61.66%)\n",
            "Epoch [32/150], Step [1/32], Loss: 2.4316\n",
            "Epoch [33/150], Step [1/32], Loss: 2.4224\n",
            "Epoch [34/150], Step [1/32], Loss: 2.4143\n",
            "Epoch [35/150], Step [1/32], Loss: 2.4069\n",
            "Epoch [36/150], Step [1/32], Loss: 2.4007\n",
            "Epoch [37/150], Step [1/32], Loss: 2.4112\n",
            "Epoch [38/150], Step [1/32], Loss: 2.4078\n",
            "Epoch [39/150], Step [1/32], Loss: 2.3960\n",
            "Epoch [40/150], Step [1/32], Loss: 2.4079\n",
            "Epoch [41/150], Step [1/32], Loss: 2.3922\n",
            "Accuracy of the network on test set: 67.09% (67.09%)\n",
            "Epoch [42/150], Step [1/32], Loss: 2.3670\n",
            "Epoch [43/150], Step [1/32], Loss: 2.3848\n",
            "Epoch [44/150], Step [1/32], Loss: 2.4072\n",
            "Epoch [45/150], Step [1/32], Loss: 2.3878\n",
            "Epoch [46/150], Step [1/32], Loss: 2.3854\n",
            "Epoch [47/150], Step [1/32], Loss: 2.3923\n",
            "Epoch [48/150], Step [1/32], Loss: 2.3926\n",
            "Epoch [49/150], Step [1/32], Loss: 2.3913\n",
            "Epoch [50/150], Step [1/32], Loss: 2.3869\n",
            "Epoch [51/150], Step [1/32], Loss: 2.3876\n",
            "Accuracy of the network on test set: 66.03% (66.03%)\n",
            "Epoch [52/150], Step [1/32], Loss: 2.3875\n",
            "Epoch [53/150], Step [1/32], Loss: 2.3784\n",
            "Epoch [54/150], Step [1/32], Loss: 2.3672\n",
            "Epoch [55/150], Step [1/32], Loss: 2.3539\n",
            "Epoch [56/150], Step [1/32], Loss: 2.3806\n",
            "Epoch [57/150], Step [1/32], Loss: 2.3677\n",
            "Epoch [58/150], Step [1/32], Loss: 2.3555\n",
            "Epoch [59/150], Step [1/32], Loss: 2.3654\n",
            "Epoch [60/150], Step [1/32], Loss: 2.3752\n",
            "Epoch [61/150], Step [1/32], Loss: 2.3697\n",
            "Accuracy of the network on test set: 66.87% (66.87%)\n",
            "Epoch [62/150], Step [1/32], Loss: 2.3620\n",
            "Epoch [63/150], Step [1/32], Loss: 2.3726\n",
            "Epoch [64/150], Step [1/32], Loss: 2.3617\n",
            "Epoch [65/150], Step [1/32], Loss: 2.3667\n",
            "Epoch [66/150], Step [1/32], Loss: 2.3621\n",
            "Epoch [67/150], Step [1/32], Loss: 2.3645\n",
            "Epoch [68/150], Step [1/32], Loss: 2.3491\n",
            "Epoch [69/150], Step [1/32], Loss: 2.3601\n",
            "Epoch [70/150], Step [1/32], Loss: 2.3578\n",
            "Epoch [71/150], Step [1/32], Loss: 2.3768\n",
            "Accuracy of the network on test set: 67.58% (67.58%)\n",
            "Epoch [72/150], Step [1/32], Loss: 2.3572\n",
            "Epoch [73/150], Step [1/32], Loss: 2.3568\n",
            "Epoch [74/150], Step [1/32], Loss: 2.3579\n",
            "Epoch [75/150], Step [1/32], Loss: 2.3620\n",
            "Epoch [76/150], Step [1/32], Loss: 2.3566\n",
            "Epoch [77/150], Step [1/32], Loss: 2.3609\n",
            "Epoch [78/150], Step [1/32], Loss: 2.3520\n",
            "Epoch [79/150], Step [1/32], Loss: 2.3663\n",
            "Epoch [80/150], Step [1/32], Loss: 2.3453\n",
            "Epoch [81/150], Step [1/32], Loss: 2.3448\n",
            "Accuracy of the network on test set: 68.77% (68.77%)\n",
            "Epoch [82/150], Step [1/32], Loss: 2.3443\n",
            "Epoch [83/150], Step [1/32], Loss: 2.3566\n",
            "Epoch [84/150], Step [1/32], Loss: 2.3514\n",
            "Epoch [85/150], Step [1/32], Loss: 2.3393\n",
            "Epoch [86/150], Step [1/32], Loss: 2.3519\n",
            "Epoch [87/150], Step [1/32], Loss: 2.3483\n",
            "Epoch [88/150], Step [1/32], Loss: 2.3533\n",
            "Epoch [89/150], Step [1/32], Loss: 2.3625\n",
            "Epoch [90/150], Step [1/32], Loss: 2.3517\n",
            "Epoch [91/150], Step [1/32], Loss: 2.3431\n",
            "Accuracy of the network on test set: 69.26% (69.26%)\n",
            "Epoch [92/150], Step [1/32], Loss: 2.3488\n",
            "Epoch [93/150], Step [1/32], Loss: 2.3649\n",
            "Epoch [94/150], Step [1/32], Loss: 2.3442\n",
            "Epoch [95/150], Step [1/32], Loss: 2.3419\n",
            "Epoch [96/150], Step [1/32], Loss: 2.3542\n",
            "Epoch [97/150], Step [1/32], Loss: 2.3393\n",
            "Epoch [98/150], Step [1/32], Loss: 2.3317\n",
            "Epoch [99/150], Step [1/32], Loss: 2.3549\n",
            "Epoch [100/150], Step [1/32], Loss: 2.3424\n",
            "Epoch [101/150], Step [1/32], Loss: 2.3448\n",
            "Accuracy of the network on test set: 69.04% (69.04%)\n",
            "Epoch [102/150], Step [1/32], Loss: 2.3380\n",
            "Epoch [103/150], Step [1/32], Loss: 2.3442\n",
            "Epoch [104/150], Step [1/32], Loss: 2.3241\n",
            "Epoch [105/150], Step [1/32], Loss: 2.3364\n",
            "Epoch [106/150], Step [1/32], Loss: 2.3445\n",
            "Epoch [107/150], Step [1/32], Loss: 2.3314\n",
            "Epoch [108/150], Step [1/32], Loss: 2.3415\n",
            "Epoch [109/150], Step [1/32], Loss: 2.3572\n",
            "Epoch [110/150], Step [1/32], Loss: 2.3379\n",
            "Epoch [111/150], Step [1/32], Loss: 2.3458\n",
            "Accuracy of the network on test set: 69.21% (69.21%)\n",
            "Epoch [112/150], Step [1/32], Loss: 2.3312\n",
            "Epoch [113/150], Step [1/32], Loss: 2.3423\n",
            "Epoch [114/150], Step [1/32], Loss: 2.3408\n",
            "Epoch [115/150], Step [1/32], Loss: 2.3490\n",
            "Epoch [116/150], Step [1/32], Loss: 2.3424\n",
            "Epoch [117/150], Step [1/32], Loss: 2.3338\n",
            "Epoch [118/150], Step [1/32], Loss: 2.3321\n",
            "Epoch [119/150], Step [1/32], Loss: 2.3282\n",
            "Epoch [120/150], Step [1/32], Loss: 2.3410\n",
            "Epoch [121/150], Step [1/32], Loss: 2.3552\n",
            "Accuracy of the network on test set: 69.52% (69.52%)\n",
            "Epoch [122/150], Step [1/32], Loss: 2.3467\n",
            "Epoch [123/150], Step [1/32], Loss: 2.3420\n",
            "Epoch [124/150], Step [1/32], Loss: 2.3275\n",
            "Epoch [125/150], Step [1/32], Loss: 2.3524\n",
            "Epoch [126/150], Step [1/32], Loss: 2.3324\n",
            "Epoch [127/150], Step [1/32], Loss: 2.3461\n",
            "Epoch [128/150], Step [1/32], Loss: 2.3163\n",
            "Epoch [129/150], Step [1/32], Loss: 2.3288\n",
            "Epoch [130/150], Step [1/32], Loss: 2.3291\n",
            "Epoch [131/150], Step [1/32], Loss: 2.3434\n",
            "Accuracy of the network on test set: 69.61% (69.61%)\n",
            "Epoch [132/150], Step [1/32], Loss: 2.3294\n",
            "Epoch [133/150], Step [1/32], Loss: 2.3208\n",
            "Epoch [134/150], Step [1/32], Loss: 2.3462\n",
            "Epoch [135/150], Step [1/32], Loss: 2.3298\n",
            "Epoch [136/150], Step [1/32], Loss: 2.3415\n",
            "Epoch [137/150], Step [1/32], Loss: 2.3251\n",
            "Epoch [138/150], Step [1/32], Loss: 2.3320\n",
            "Epoch [139/150], Step [1/32], Loss: 2.3220\n",
            "Epoch [140/150], Step [1/32], Loss: 2.3321\n",
            "Epoch [141/150], Step [1/32], Loss: 2.3434\n",
            "Accuracy of the network on test set: 69.79% (69.79%)\n",
            "Epoch [142/150], Step [1/32], Loss: 2.3508\n",
            "Epoch [143/150], Step [1/32], Loss: 2.3238\n",
            "Epoch [144/150], Step [1/32], Loss: 2.3343\n",
            "Epoch [145/150], Step [1/32], Loss: 2.3347\n",
            "Epoch [146/150], Step [1/32], Loss: 2.3239\n",
            "Epoch [147/150], Step [1/32], Loss: 2.3163\n",
            "Epoch [148/150], Step [1/32], Loss: 2.3341\n",
            "Epoch [149/150], Step [1/32], Loss: 2.3268\n",
            "Epoch [150/150], Step [1/32], Loss: 2.3286\n",
            "Training time: 2372.3119437570003\n",
            "2372.3140506559994\n",
            "Accuracy of the network on test set: 68.73% (68.73%)\n",
            "Accuracy of the network on 2 classes: 79.99%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/4\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 150\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_2(neurons_in=512, neurons_h1=256, neurons_h2=128, dropout=0.5, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)\n",
        "accuracy_2class(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqzOsOnXTQhU",
        "outputId": "bf9a87cd-3a7f-49c9-cdce-cd15b7024f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([64, 256, 1, 512]) torch.Size([256]) tensor([16, 13,  2, 16, 11, 17, 11,  0,  1,  0, 17,  9,  3,  2,  5, 18,  8,  8,\n",
            "        12, 13,  5, 18,  5,  1, 13,  8,  0,  2,  8, 16, 17,  4,  8,  1, 17, 16,\n",
            "         0, 14, 16,  9,  2,  1, 16, 19,  7,  8, 19, 16,  5, 17, 18, 14, 13, 16,\n",
            "         9, 16,  6, 19,  0,  9, 13,  2, 12, 17, 12,  1,  2,  3,  1, 12, 18, 12,\n",
            "         2, 18,  8, 10, 11,  3,  9, 14, 18, 13, 15,  3,  2, 19,  4,  3, 10,  2,\n",
            "         3, 13, 10,  6, 18, 18,  5, 16, 19,  4, 19, 10,  3, 16, 17,  7, 10,  5,\n",
            "        11,  2,  5,  1, 14,  2, 11, 14,  1,  6, 15, 18, 19, 13,  4,  3, 18, 16,\n",
            "         4, 11,  7,  7, 14,  4, 10, 14, 15,  6,  0,  5,  1,  0,  7,  6, 19,  5,\n",
            "        11,  3,  3, 16, 19, 17,  6,  0,  9, 19, 10,  5, 16, 18,  2,  0, 16,  4,\n",
            "        10,  6,  5,  6, 11, 15, 10,  6,  9,  0, 10,  9, 11, 13,  7, 12,  2,  5,\n",
            "        19, 11, 10, 16,  0, 11,  1, 12, 14, 13,  7,  0, 14, 17,  6, 18, 14, 10,\n",
            "         3,  7,  2,  3,  9, 12, 14, 12, 15, 13,  8,  7,  3,  7, 18, 11,  5,  6,\n",
            "         5,  3, 14,  5, 13,  8,  5,  6, 11, 18,  9,  7,  8,  9,  4,  4, 15, 18,\n",
            "         7, 16,  1, 10,  0,  2, 16, 10,  6,  6,  2, 13,  6, 10, 11, 12, 14,  3,\n",
            "         4, 18,  9,  7])\n",
            "Epoch [1/150], Step [1/32], Loss: 3.0138\n",
            "Accuracy of the network on test set: 17.27% (17.27%)\n",
            "Epoch [2/150], Step [1/32], Loss: 2.9169\n",
            "Epoch [3/150], Step [1/32], Loss: 2.7535\n",
            "Epoch [4/150], Step [1/32], Loss: 2.6664\n",
            "Epoch [5/150], Step [1/32], Loss: 2.6021\n",
            "Epoch [6/150], Step [1/32], Loss: 2.5898\n",
            "Epoch [7/150], Step [1/32], Loss: 2.5600\n",
            "Epoch [8/150], Step [1/32], Loss: 2.5403\n",
            "Epoch [9/150], Step [1/32], Loss: 2.5346\n",
            "Epoch [10/150], Step [1/32], Loss: 2.4970\n",
            "Epoch [11/150], Step [1/32], Loss: 2.5044\n",
            "Accuracy of the network on test set: 51.50% (51.50%)\n",
            "Epoch [12/150], Step [1/32], Loss: 2.4891\n",
            "Epoch [13/150], Step [1/32], Loss: 2.4706\n",
            "Epoch [14/150], Step [1/32], Loss: 2.4717\n",
            "Epoch [15/150], Step [1/32], Loss: 2.4547\n",
            "Epoch [16/150], Step [1/32], Loss: 2.4385\n",
            "Epoch [17/150], Step [1/32], Loss: 2.4558\n",
            "Epoch [18/150], Step [1/32], Loss: 2.4547\n",
            "Epoch [19/150], Step [1/32], Loss: 2.4537\n",
            "Epoch [20/150], Step [1/32], Loss: 2.4303\n",
            "Epoch [21/150], Step [1/32], Loss: 2.4267\n",
            "Accuracy of the network on test set: 56.01% (56.01%)\n",
            "Epoch [22/150], Step [1/32], Loss: 2.4170\n",
            "Epoch [23/150], Step [1/32], Loss: 2.4275\n",
            "Epoch [24/150], Step [1/32], Loss: 2.3944\n",
            "Epoch [25/150], Step [1/32], Loss: 2.3968\n",
            "Epoch [26/150], Step [1/32], Loss: 2.4036\n",
            "Epoch [27/150], Step [1/32], Loss: 2.3872\n",
            "Epoch [28/150], Step [1/32], Loss: 2.3743\n",
            "Epoch [29/150], Step [1/32], Loss: 2.3968\n",
            "Epoch [30/150], Step [1/32], Loss: 2.3791\n",
            "Epoch [31/150], Step [1/32], Loss: 2.3753\n",
            "Accuracy of the network on test set: 59.28% (59.28%)\n",
            "Epoch [32/150], Step [1/32], Loss: 2.3826\n",
            "Epoch [33/150], Step [1/32], Loss: 2.3775\n",
            "Epoch [34/150], Step [1/32], Loss: 2.3846\n",
            "Epoch [35/150], Step [1/32], Loss: 2.3653\n",
            "Epoch [36/150], Step [1/32], Loss: 2.3677\n",
            "Epoch [37/150], Step [1/32], Loss: 2.3638\n",
            "Epoch [38/150], Step [1/32], Loss: 2.3767\n",
            "Epoch [39/150], Step [1/32], Loss: 2.3706\n",
            "Epoch [40/150], Step [1/32], Loss: 2.3623\n",
            "Epoch [41/150], Step [1/32], Loss: 2.3610\n",
            "Accuracy of the network on test set: 61.84% (61.84%)\n",
            "Epoch [42/150], Step [1/32], Loss: 2.3452\n",
            "Epoch [43/150], Step [1/32], Loss: 2.3794\n",
            "Epoch [44/150], Step [1/32], Loss: 2.3508\n",
            "Epoch [45/150], Step [1/32], Loss: 2.3614\n",
            "Epoch [46/150], Step [1/32], Loss: 2.3685\n",
            "Epoch [47/150], Step [1/32], Loss: 2.3627\n",
            "Epoch [48/150], Step [1/32], Loss: 2.3262\n",
            "Epoch [49/150], Step [1/32], Loss: 2.3549\n",
            "Epoch [50/150], Step [1/32], Loss: 2.3449\n",
            "Epoch [51/150], Step [1/32], Loss: 2.3601\n",
            "Accuracy of the network on test set: 64.84% (64.84%)\n",
            "Epoch [52/150], Step [1/32], Loss: 2.3520\n",
            "Epoch [53/150], Step [1/32], Loss: 2.3548\n",
            "Epoch [54/150], Step [1/32], Loss: 2.3310\n",
            "Epoch [55/150], Step [1/32], Loss: 2.3500\n",
            "Epoch [56/150], Step [1/32], Loss: 2.3564\n",
            "Epoch [57/150], Step [1/32], Loss: 2.3429\n",
            "Epoch [58/150], Step [1/32], Loss: 2.3178\n",
            "Epoch [59/150], Step [1/32], Loss: 2.3428\n",
            "Epoch [60/150], Step [1/32], Loss: 2.3310\n",
            "Epoch [61/150], Step [1/32], Loss: 2.3299\n",
            "Accuracy of the network on test set: 67.27% (67.27%)\n",
            "Epoch [62/150], Step [1/32], Loss: 2.3332\n",
            "Epoch [63/150], Step [1/32], Loss: 2.3318\n",
            "Epoch [64/150], Step [1/32], Loss: 2.3231\n",
            "Epoch [65/150], Step [1/32], Loss: 2.3193\n",
            "Epoch [66/150], Step [1/32], Loss: 2.3229\n",
            "Epoch [67/150], Step [1/32], Loss: 2.3141\n",
            "Epoch [68/150], Step [1/32], Loss: 2.3174\n",
            "Epoch [69/150], Step [1/32], Loss: 2.3186\n",
            "Epoch [70/150], Step [1/32], Loss: 2.3181\n",
            "Epoch [71/150], Step [1/32], Loss: 2.3180\n",
            "Accuracy of the network on test set: 68.11% (68.11%)\n",
            "Epoch [72/150], Step [1/32], Loss: 2.3102\n",
            "Epoch [73/150], Step [1/32], Loss: 2.3092\n",
            "Epoch [74/150], Step [1/32], Loss: 2.3093\n",
            "Epoch [75/150], Step [1/32], Loss: 2.3204\n",
            "Epoch [76/150], Step [1/32], Loss: 2.3187\n",
            "Epoch [77/150], Step [1/32], Loss: 2.3182\n",
            "Epoch [78/150], Step [1/32], Loss: 2.3158\n",
            "Epoch [79/150], Step [1/32], Loss: 2.3173\n",
            "Epoch [80/150], Step [1/32], Loss: 2.3162\n",
            "Epoch [81/150], Step [1/32], Loss: 2.3139\n",
            "Accuracy of the network on test set: 70.36% (70.36%)\n",
            "Epoch [82/150], Step [1/32], Loss: 2.3201\n",
            "Epoch [83/150], Step [1/32], Loss: 2.3300\n",
            "Epoch [84/150], Step [1/32], Loss: 2.3005\n",
            "Epoch [85/150], Step [1/32], Loss: 2.3250\n",
            "Epoch [86/150], Step [1/32], Loss: 2.2945\n",
            "Epoch [87/150], Step [1/32], Loss: 2.3171\n",
            "Epoch [88/150], Step [1/32], Loss: 2.3139\n",
            "Epoch [89/150], Step [1/32], Loss: 2.2972\n",
            "Epoch [90/150], Step [1/32], Loss: 2.2998\n",
            "Epoch [91/150], Step [1/32], Loss: 2.3079\n",
            "Accuracy of the network on test set: 71.25% (71.25%)\n",
            "Epoch [92/150], Step [1/32], Loss: 2.3190\n",
            "Epoch [93/150], Step [1/32], Loss: 2.3072\n",
            "Epoch [94/150], Step [1/32], Loss: 2.2957\n",
            "Epoch [95/150], Step [1/32], Loss: 2.3185\n",
            "Epoch [96/150], Step [1/32], Loss: 2.3130\n",
            "Epoch [97/150], Step [1/32], Loss: 2.2958\n",
            "Epoch [98/150], Step [1/32], Loss: 2.2946\n",
            "Epoch [99/150], Step [1/32], Loss: 2.3012\n",
            "Epoch [100/150], Step [1/32], Loss: 2.2945\n",
            "Epoch [101/150], Step [1/32], Loss: 2.3054\n",
            "Accuracy of the network on test set: 71.55% (71.55%)\n",
            "Epoch [102/150], Step [1/32], Loss: 2.2962\n",
            "Epoch [103/150], Step [1/32], Loss: 2.3001\n",
            "Epoch [104/150], Step [1/32], Loss: 2.2974\n",
            "Epoch [105/150], Step [1/32], Loss: 2.2854\n",
            "Epoch [106/150], Step [1/32], Loss: 2.2968\n",
            "Epoch [107/150], Step [1/32], Loss: 2.2899\n",
            "Epoch [108/150], Step [1/32], Loss: 2.2842\n",
            "Epoch [109/150], Step [1/32], Loss: 2.3031\n",
            "Epoch [110/150], Step [1/32], Loss: 2.3026\n",
            "Epoch [111/150], Step [1/32], Loss: 2.3107\n",
            "Accuracy of the network on test set: 72.57% (72.57%)\n",
            "Epoch [112/150], Step [1/32], Loss: 2.2928\n",
            "Epoch [113/150], Step [1/32], Loss: 2.2946\n",
            "Epoch [114/150], Step [1/32], Loss: 2.2911\n",
            "Epoch [115/150], Step [1/32], Loss: 2.2957\n",
            "Epoch [116/150], Step [1/32], Loss: 2.2892\n",
            "Epoch [117/150], Step [1/32], Loss: 2.2903\n",
            "Epoch [118/150], Step [1/32], Loss: 2.2946\n",
            "Epoch [119/150], Step [1/32], Loss: 2.2872\n",
            "Epoch [120/150], Step [1/32], Loss: 2.2923\n",
            "Epoch [121/150], Step [1/32], Loss: 2.2936\n",
            "Accuracy of the network on test set: 72.84% (72.84%)\n",
            "Epoch [122/150], Step [1/32], Loss: 2.3054\n",
            "Epoch [123/150], Step [1/32], Loss: 2.2886\n",
            "Epoch [124/150], Step [1/32], Loss: 2.2930\n",
            "Epoch [125/150], Step [1/32], Loss: 2.2928\n",
            "Epoch [126/150], Step [1/32], Loss: 2.2822\n",
            "Epoch [127/150], Step [1/32], Loss: 2.2903\n",
            "Epoch [128/150], Step [1/32], Loss: 2.2989\n",
            "Epoch [129/150], Step [1/32], Loss: 2.2848\n",
            "Epoch [130/150], Step [1/32], Loss: 2.2988\n",
            "Epoch [131/150], Step [1/32], Loss: 2.2900\n",
            "Accuracy of the network on test set: 72.57% (72.57%)\n",
            "Epoch [132/150], Step [1/32], Loss: 2.2899\n",
            "Epoch [133/150], Step [1/32], Loss: 2.2964\n",
            "Epoch [134/150], Step [1/32], Loss: 2.2939\n",
            "Epoch [135/150], Step [1/32], Loss: 2.2827\n",
            "Epoch [136/150], Step [1/32], Loss: 2.2994\n",
            "Epoch [137/150], Step [1/32], Loss: 2.2896\n",
            "Epoch [138/150], Step [1/32], Loss: 2.2949\n",
            "Epoch [139/150], Step [1/32], Loss: 2.2935\n",
            "Epoch [140/150], Step [1/32], Loss: 2.2855\n",
            "Epoch [141/150], Step [1/32], Loss: 2.2876\n",
            "Accuracy of the network on test set: 73.50% (73.50%)\n",
            "Epoch [142/150], Step [1/32], Loss: 2.2896\n",
            "Epoch [143/150], Step [1/32], Loss: 2.2842\n",
            "Epoch [144/150], Step [1/32], Loss: 2.2875\n",
            "Epoch [145/150], Step [1/32], Loss: 2.2721\n",
            "Epoch [146/150], Step [1/32], Loss: 2.2798\n",
            "Epoch [147/150], Step [1/32], Loss: 2.2794\n",
            "Epoch [148/150], Step [1/32], Loss: 2.2757\n",
            "Epoch [149/150], Step [1/32], Loss: 2.2922\n",
            "Epoch [150/150], Step [1/32], Loss: 2.2828\n",
            "Training time: 2529.149492806\n",
            "2529.1514411549997\n",
            "Accuracy of the network on test set: 72.79% (72.79%)\n",
            "Accuracy of the network on 2 classes: 82.16%\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256 # gives the best tradeoff between speed (~10 sec per epoch on T4 GPU) and number of weight updates (32 steps per 10 sec)\n",
        "dt = 62_500/4\n",
        "transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.CropTime(max=1e6), # all timestamp units in microseconds in Tonic\n",
        "                transforms.Downsample(spatial_factor=512.0/700.0),\n",
        "                transforms.ToFrame(\n",
        "                    sensor_size=(512,1,1),\n",
        "                    time_window=dt,\n",
        "                    include_incomplete=True,\n",
        "                ),\n",
        "            ]\n",
        "        )\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path='./cache/shd/train/512_'+str(dt)+'/')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path='./cache/shd/test/512_'+str(dt)+'/')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  break\n",
        "\n",
        "learning_rate = 0.001\n",
        "num_epochs = 150\n",
        "\n",
        "# Model, loss function, and optimizer\n",
        "model = FCN_3(neurons_in=512, neurons_h1=256, neurons_h2=128, neurons_h3=64, bn=False).to(device)\n",
        "criterion = SF.ce_rate_loss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=100)\n",
        "\n",
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs,    testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)\n",
        "accuracy_2class(model, testloader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_B447_tcqiUc",
        "outputId": "199e2cee-6080-4977-ed0b-a6652f18995c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/150], Step [1/32], Loss: 2.2848\n",
            "Accuracy of the network on test set: 73.14% (73.14%)\n",
            "Epoch [2/150], Step [1/32], Loss: 2.2792\n",
            "Epoch [3/150], Step [1/32], Loss: 2.2850\n",
            "Epoch [4/150], Step [1/32], Loss: 2.2729\n",
            "Epoch [5/150], Step [1/32], Loss: 2.2957\n",
            "Epoch [6/150], Step [1/32], Loss: 2.2897\n",
            "Epoch [7/150], Step [1/32], Loss: 2.2901\n",
            "Epoch [8/150], Step [1/32], Loss: 2.2650\n",
            "Epoch [9/150], Step [1/32], Loss: 2.2754\n",
            "Epoch [10/150], Step [1/32], Loss: 2.2867\n",
            "Epoch [11/150], Step [1/32], Loss: 2.2778\n",
            "Accuracy of the network on test set: 73.45% (73.45%)\n",
            "Epoch [12/150], Step [1/32], Loss: 2.2870\n",
            "Epoch [13/150], Step [1/32], Loss: 2.2849\n",
            "Epoch [14/150], Step [1/32], Loss: 2.2751\n",
            "Epoch [15/150], Step [1/32], Loss: 2.2959\n",
            "Epoch [16/150], Step [1/32], Loss: 2.2709\n",
            "Epoch [17/150], Step [1/32], Loss: 2.2769\n",
            "Epoch [18/150], Step [1/32], Loss: 2.2815\n",
            "Epoch [19/150], Step [1/32], Loss: 2.2752\n",
            "Epoch [20/150], Step [1/32], Loss: 2.2796\n",
            "Epoch [21/150], Step [1/32], Loss: 2.2690\n",
            "Accuracy of the network on test set: 73.45% (73.45%)\n",
            "Epoch [22/150], Step [1/32], Loss: 2.2839\n",
            "Epoch [23/150], Step [1/32], Loss: 2.2751\n",
            "Epoch [24/150], Step [1/32], Loss: 2.2809\n",
            "Epoch [25/150], Step [1/32], Loss: 2.2629\n",
            "Epoch [26/150], Step [1/32], Loss: 2.2712\n",
            "Epoch [27/150], Step [1/32], Loss: 2.2829\n",
            "Epoch [28/150], Step [1/32], Loss: 2.2786\n",
            "Epoch [29/150], Step [1/32], Loss: 2.2756\n",
            "Epoch [30/150], Step [1/32], Loss: 2.2785\n",
            "Epoch [31/150], Step [1/32], Loss: 2.2838\n",
            "Accuracy of the network on test set: 73.32% (73.32%)\n",
            "Epoch [32/150], Step [1/32], Loss: 2.2832\n",
            "Epoch [33/150], Step [1/32], Loss: 2.2733\n",
            "Epoch [34/150], Step [1/32], Loss: 2.2748\n",
            "Epoch [35/150], Step [1/32], Loss: 2.2729\n",
            "Epoch [36/150], Step [1/32], Loss: 2.2770\n",
            "Epoch [37/150], Step [1/32], Loss: 2.2660\n",
            "Epoch [38/150], Step [1/32], Loss: 2.2714\n",
            "Epoch [39/150], Step [1/32], Loss: 2.2663\n",
            "Epoch [40/150], Step [1/32], Loss: 2.2799\n",
            "Epoch [41/150], Step [1/32], Loss: 2.2829\n",
            "Accuracy of the network on test set: 74.16% (74.16%)\n",
            "Epoch [42/150], Step [1/32], Loss: 2.2699\n",
            "Epoch [43/150], Step [1/32], Loss: 2.2816\n",
            "Epoch [44/150], Step [1/32], Loss: 2.2591\n",
            "Epoch [45/150], Step [1/32], Loss: 2.2551\n",
            "Epoch [46/150], Step [1/32], Loss: 2.2739\n",
            "Epoch [47/150], Step [1/32], Loss: 2.2743\n",
            "Epoch [48/150], Step [1/32], Loss: 2.2742\n",
            "Epoch [49/150], Step [1/32], Loss: 2.2741\n",
            "Epoch [50/150], Step [1/32], Loss: 2.2713\n",
            "Epoch [51/150], Step [1/32], Loss: 2.2714\n",
            "Accuracy of the network on test set: 73.45% (73.45%)\n",
            "Epoch [52/150], Step [1/32], Loss: 2.2733\n",
            "Epoch [53/150], Step [1/32], Loss: 2.2643\n",
            "Epoch [54/150], Step [1/32], Loss: 2.2679\n",
            "Epoch [55/150], Step [1/32], Loss: 2.2723\n",
            "Epoch [56/150], Step [1/32], Loss: 2.2741\n",
            "Epoch [57/150], Step [1/32], Loss: 2.2659\n",
            "Epoch [58/150], Step [1/32], Loss: 2.2695\n",
            "Epoch [59/150], Step [1/32], Loss: 2.2808\n",
            "Epoch [60/150], Step [1/32], Loss: 2.2653\n",
            "Epoch [61/150], Step [1/32], Loss: 2.2712\n",
            "Accuracy of the network on test set: 74.34% (74.34%)\n",
            "Epoch [62/150], Step [1/32], Loss: 2.2653\n",
            "Epoch [63/150], Step [1/32], Loss: 2.2830\n",
            "Epoch [64/150], Step [1/32], Loss: 2.2645\n",
            "Epoch [65/150], Step [1/32], Loss: 2.2651\n",
            "Epoch [66/150], Step [1/32], Loss: 2.2666\n",
            "Epoch [67/150], Step [1/32], Loss: 2.2763\n",
            "Epoch [68/150], Step [1/32], Loss: 2.2644\n",
            "Epoch [69/150], Step [1/32], Loss: 2.2791\n",
            "Epoch [70/150], Step [1/32], Loss: 2.2673\n",
            "Epoch [71/150], Step [1/32], Loss: 2.2736\n",
            "Accuracy of the network on test set: 74.20% (74.20%)\n",
            "Epoch [72/150], Step [1/32], Loss: 2.2727\n",
            "Epoch [73/150], Step [1/32], Loss: 2.2650\n",
            "Epoch [74/150], Step [1/32], Loss: 2.2676\n",
            "Epoch [75/150], Step [1/32], Loss: 2.2678\n",
            "Epoch [76/150], Step [1/32], Loss: 2.2570\n",
            "Epoch [77/150], Step [1/32], Loss: 2.2633\n",
            "Epoch [78/150], Step [1/32], Loss: 2.2704\n",
            "Epoch [79/150], Step [1/32], Loss: 2.2676\n",
            "Epoch [80/150], Step [1/32], Loss: 2.2631\n",
            "Epoch [81/150], Step [1/32], Loss: 2.2644\n",
            "Accuracy of the network on test set: 73.94% (73.94%)\n",
            "Epoch [82/150], Step [1/32], Loss: 2.2630\n",
            "Epoch [83/150], Step [1/32], Loss: 2.2576\n",
            "Epoch [84/150], Step [1/32], Loss: 2.2698\n",
            "Epoch [85/150], Step [1/32], Loss: 2.2562\n",
            "Epoch [86/150], Step [1/32], Loss: 2.2682\n",
            "Epoch [87/150], Step [1/32], Loss: 2.2592\n",
            "Epoch [88/150], Step [1/32], Loss: 2.2595\n",
            "Epoch [89/150], Step [1/32], Loss: 2.2602\n",
            "Epoch [90/150], Step [1/32], Loss: 2.2522\n",
            "Epoch [91/150], Step [1/32], Loss: 2.2581\n",
            "Accuracy of the network on test set: 73.76% (73.76%)\n",
            "Epoch [92/150], Step [1/32], Loss: 2.2665\n",
            "Epoch [93/150], Step [1/32], Loss: 2.2813\n",
            "Epoch [94/150], Step [1/32], Loss: 2.2666\n",
            "Epoch [95/150], Step [1/32], Loss: 2.2509\n",
            "Epoch [96/150], Step [1/32], Loss: 2.2632\n",
            "Epoch [97/150], Step [1/32], Loss: 2.2583\n",
            "Epoch [98/150], Step [1/32], Loss: 2.2557\n",
            "Epoch [99/150], Step [1/32], Loss: 2.2568\n",
            "Epoch [100/150], Step [1/32], Loss: 2.2716\n",
            "Epoch [101/150], Step [1/32], Loss: 2.2590\n",
            "Accuracy of the network on test set: 74.29% (74.29%)\n",
            "Epoch [102/150], Step [1/32], Loss: 2.2738\n",
            "Epoch [103/150], Step [1/32], Loss: 2.2604\n",
            "Epoch [104/150], Step [1/32], Loss: 2.2487\n",
            "Epoch [105/150], Step [1/32], Loss: 2.2685\n",
            "Epoch [106/150], Step [1/32], Loss: 2.2480\n",
            "Epoch [107/150], Step [1/32], Loss: 2.2425\n",
            "Epoch [108/150], Step [1/32], Loss: 2.2530\n",
            "Epoch [109/150], Step [1/32], Loss: 2.2552\n",
            "Epoch [110/150], Step [1/32], Loss: 2.2589\n",
            "Epoch [111/150], Step [1/32], Loss: 2.2517\n",
            "Accuracy of the network on test set: 74.29% (74.29%)\n",
            "Epoch [112/150], Step [1/32], Loss: 2.2432\n",
            "Epoch [113/150], Step [1/32], Loss: 2.2574\n",
            "Epoch [114/150], Step [1/32], Loss: 2.2486\n",
            "Epoch [115/150], Step [1/32], Loss: 2.2671\n",
            "Epoch [116/150], Step [1/32], Loss: 2.2532\n",
            "Epoch [117/150], Step [1/32], Loss: 2.2535\n",
            "Epoch [118/150], Step [1/32], Loss: 2.2461\n",
            "Epoch [119/150], Step [1/32], Loss: 2.2573\n",
            "Epoch [120/150], Step [1/32], Loss: 2.2443\n",
            "Epoch [121/150], Step [1/32], Loss: 2.2599\n",
            "Accuracy of the network on test set: 74.16% (74.16%)\n",
            "Epoch [122/150], Step [1/32], Loss: 2.2517\n",
            "Epoch [123/150], Step [1/32], Loss: 2.2466\n",
            "Epoch [124/150], Step [1/32], Loss: 2.2532\n",
            "Epoch [125/150], Step [1/32], Loss: 2.2530\n",
            "Epoch [126/150], Step [1/32], Loss: 2.2507\n",
            "Epoch [127/150], Step [1/32], Loss: 2.2576\n",
            "Epoch [128/150], Step [1/32], Loss: 2.2497\n",
            "Epoch [129/150], Step [1/32], Loss: 2.2488\n",
            "Epoch [130/150], Step [1/32], Loss: 2.2487\n",
            "Epoch [131/150], Step [1/32], Loss: 2.2488\n",
            "Accuracy of the network on test set: 73.98% (73.98%)\n",
            "Epoch [132/150], Step [1/32], Loss: 2.2498\n",
            "Epoch [133/150], Step [1/32], Loss: 2.2552\n",
            "Epoch [134/150], Step [1/32], Loss: 2.2547\n",
            "Epoch [135/150], Step [1/32], Loss: 2.2474\n",
            "Epoch [136/150], Step [1/32], Loss: 2.2572\n",
            "Epoch [137/150], Step [1/32], Loss: 2.2500\n",
            "Epoch [138/150], Step [1/32], Loss: 2.2556\n",
            "Epoch [139/150], Step [1/32], Loss: 2.2436\n",
            "Epoch [140/150], Step [1/32], Loss: 2.2506\n",
            "Epoch [141/150], Step [1/32], Loss: 2.2508\n",
            "Accuracy of the network on test set: 74.56% (74.56%)\n",
            "Epoch [142/150], Step [1/32], Loss: 2.2420\n",
            "Epoch [143/150], Step [1/32], Loss: 2.2374\n",
            "Epoch [144/150], Step [1/32], Loss: 2.2496\n",
            "Epoch [145/150], Step [1/32], Loss: 2.2413\n",
            "Epoch [146/150], Step [1/32], Loss: 2.2473\n",
            "Epoch [147/150], Step [1/32], Loss: 2.2475\n",
            "Epoch [148/150], Step [1/32], Loss: 2.2345\n",
            "Epoch [149/150], Step [1/32], Loss: 2.2401\n",
            "Epoch [150/150], Step [1/32], Loss: 2.2439\n",
            "Training time: 2545.2031529159995\n",
            "2545.2052624590015\n",
            "Accuracy of the network on test set: 74.51% (74.51%)\n",
            "Accuracy of the network on 2 classes: 82.55%\n"
          ]
        }
      ],
      "source": [
        "t = time.process_time()\n",
        "train(model, criterion, optimizer, trainloader, device, num_epochs=150,    testloader=testloader, scheduler=scheduler)\n",
        "print(time.process_time() - t)\n",
        "accuracy(model, testloader, device)\n",
        "accuracy_2class(model, testloader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83fYldVbqrEp"
      },
      "source": [
        "75% accuracy\n",
        "\n",
        "* 512x256 = 128K\n",
        "* 256x128 = 32K\n",
        "* 128x64  = 8K\n",
        "*  64x20  = 1.3K\n",
        "\n",
        "* Total = 170K params\n",
        "\n",
        "64 timesteps\n",
        "\n",
        "Training time = ~5000sec = 1.5 hour"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYnGdCUdmTEc"
      },
      "outputs": [],
      "source": [
        "\n",
        "        10.22\n",
        "        spike_grad = surrogate.fast_sigmoid(slope)\n",
        "\n",
        "        self.lif2 = snn.Leaky(beta, threshold=self.thr2, reset_mechanism=self.reset_mechanism, spike_grad=spike_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGc_Y4I7tn3n"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOXgBhEWtnuv"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, seq_len, neurons_in=512, features=16, kernel_size=16, neurons_h1=256, dropout=0.0, beta=0.95):\n",
        "        super(FCN_1, self).__init__()\n",
        "        self.cnn1 = nn.Conv1d(1, features, kernel_size)\n",
        "        self.fc2 = nn.Linear(features*seq_len, neurons_h1)\n",
        "        self.fc_ = nn.Linear(neurons_h1, 20)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.lif_ = snn.Leaky(beta=beta)\n",
        "        if dropout > 0:\n",
        "          self.drop1 = nn.Dropout(p=dropout)\n",
        "        if bn:\n",
        "          self.bn1 = nn.BatchNorm1d(neurons_h1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      spk_rec = []\n",
        "      mem_rec = []\n",
        "\n",
        "      mem1 = self.lif1.init_leaky()\n",
        "      mem_ = self.lif_.init_leaky()\n",
        "\n",
        "      N = x.size(1)\n",
        "      X = x.size(3)\n",
        "\n",
        "      print(\"in\", x.size())\n",
        "      x = permute(x, (1, 3, 2, 0))              # [T, N, 1, C] -> [N, X, 1, T]\n",
        "      print(\"permute(1,3,2,0)\", x.size())\n",
        "      x = cnn1(x)                               # [NC,1T] -cnn-> [NC,KT]\n",
        "      print(\"cnn1\", x.size())\n",
        "      x = reshpe(x, (-1, N, 1, X))              # [NX,KT] -> [K*T, N, 1, X]\n",
        "      print(\"reshape(-1,N,1,X)\", x.size())\n",
        "\n",
        "      for step in range(x.size(0)):\n",
        "        cur1 = self.fc1(x[step].squeeze(1))\n",
        "        if hasattr(self, 'drop1'):\n",
        "          cur1 = self.drop1(cur1)\n",
        "        if hasattr(self, 'bn1'):\n",
        "          cur1 = self.bn1(cur1)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "        cur_ = self.fc_(spk1)\n",
        "        spk_, mem_ = self.lif_(cur_, mem_)\n",
        "        spk_rec.append(spk_)\n",
        "        mem_rec.append(mem_)\n",
        "      return torch.stack(spk_rec), torch.stack(mem_rec)\n",
        "\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, neurons_in=512, features=16, kernel_size=16, neurons_h1=256, dropout=0.0, beta=0.95):\n",
        "        super(FCN_1, self).__init__()\n",
        "        self.cnn1 = nn.Conv1d(1, features, kernel_size)\n",
        "        self.fc2 = nn.Linear(features, neurons_h1)\n",
        "        self.fc_ = nn.Linear(neurons_h1, 20)\n",
        "        self.lif1 = snn.Leaky(beta=beta)\n",
        "        self.lif_ = snn.Leaky(beta=beta)\n",
        "        if dropout > 0:\n",
        "          self.drop1 = nn.Dropout(p=dropout)\n",
        "        if bn:\n",
        "          self.bn1 = nn.BatchNorm1d(neurons_h1)\n",
        "\n",
        "    def forward(self, x):\n",
        "      spk_rec = []\n",
        "      mem_rec = []\n",
        "\n",
        "      mem1 = self.lif1.init_leaky()\n",
        "      mem_ = self.lif_.init_leaky()\n",
        "\n",
        "      N = x.size(1)\n",
        "      X = x.size(3)\n",
        "\n",
        "      print(\"in\", x.size())\n",
        "      x = permute(x, (1, 3, 2, 0))              # [T, N, 1, C] -> [N, X, 1, T]\n",
        "      print(\"permute(1,3,2,0)\", x.size())\n",
        "      x = cnn1(x)                               # [NC,1T] -cnn-> [NC,KT]\n",
        "      print(\"cnn1\", x.size())\n",
        "      x = reshpe(x, (-1, N, 1, X))              # [NX,KT] -> [K*T, N, 1, X]\n",
        "      print(\"reshape(-1,N,1,X)\", x.size())\n",
        "\n",
        "      for step in range(x.size(0)):\n",
        "        cur1 = self.fc1(x[step].squeeze(1))\n",
        "        if hasattr(self, 'drop1'):\n",
        "          cur1 = self.drop1(cur1)\n",
        "        if hasattr(self, 'bn1'):\n",
        "          cur1 = self.bn1(cur1)\n",
        "        spk1, mem1 = self.lif1(cur1, mem1)\n",
        "\n",
        "        cur_ = self.fc_(spk1)\n",
        "        spk_, mem_ = self.lif_(cur_, mem_)\n",
        "        spk_rec.append(spk_)\n",
        "        mem_rec.append(mem_)\n",
        "      return torch.stack(spk_rec), torch.stack(mem_rec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9KslLqUk4zP"
      },
      "outputs": [],
      "source": [
        "# ----------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJ38aBAwIDpw"
      },
      "outputs": [],
      "source": [
        "from tonic import datasets, transforms\n",
        "\n",
        "shd_timestep = 1e-6\n",
        "shd_channels = 700\n",
        "net_channels = 64\n",
        "net_dt = 10e-3\n",
        "sample_T = 16\n",
        "batch_size = 4096\n",
        "\n",
        "class ToRaster():\n",
        "    def __init__(self, encoding_dim, sample_T = 100):\n",
        "        self.encoding_dim = encoding_dim\n",
        "        self.sample_T = sample_T\n",
        "    def __call__(self, events):\n",
        "        # tensor has dimensions (time_steps, encoding_dim)\n",
        "        tensor = np.zeros((events[\"t\"].max()+1, self.encoding_dim), dtype=int)\n",
        "        np.add.at(tensor, (events[\"t\"], events[\"x\"]), 1)\n",
        "        return tensor[:self.sample_T,:]\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.Downsample(\n",
        "            time_factor=shd_timestep / net_dt,\n",
        "            spatial_factor=net_channels / shd_channels\n",
        "            ),\n",
        "        ToRaster(net_channels, sample_T = sample_T),\n",
        "        torch.Tensor,\n",
        "        ])\n",
        "\n",
        "trainset=datasets.SHD('data', transform=transform)\n",
        "testset=datasets.SHD('data', transform=transform, train=False)\n",
        "shd_trainset = DiskCachedDataset(trainset, cache_path=f'./cache/shd/train/raster_{sample_T}_{net_dt}_{net_channels}')\n",
        "shd_testset = DiskCachedDataset(testset, cache_path=f'./cache/shd/test/raster_{sample_T}_{net_dt}_{net_channels}')\n",
        "trainloader = DataLoader(shd_trainset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "testloader = DataLoader(shd_testset, batch_size=batch_size, collate_fn=tonic.collation.PadTensors(batch_first=False), shuffle=True)\n",
        "\n",
        "for data, labels in iter(trainloader):\n",
        "  print(data.size(), labels.size(), labels)\n",
        "  print(torch.min(data), torch.max(data), torch.mean(data), torch.var(data))\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMZQqrc1lLAX"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    total_loss = 0\n",
        "\n",
        "    for events, labels in testloader:\n",
        "        events, labels = events.to(device), labels.to(device)\n",
        "        output, _ = model(torch.Tensor(events).float())\n",
        "\n",
        "        print (output.size())\n",
        "        print (output)\n",
        "\n",
        "        sum = torch.cumsum(output, dim=1)\n",
        "\n",
        "        predicted = torch.argmax(sum[:,-1,:], 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy_test = (correct/total)*100\n",
        "\n",
        "print(f\"Test Accuracy: {accuracy_test:.3f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "000fde2d72f5492982d0f1207f9866cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "041f72dfa7c24ab2a6097dcdd2b40ab4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c7113e61d2a459bab73e7a5a89a6753",
              "IPY_MODEL_6c10bca5c4d04f5697d377a65f04df9e",
              "IPY_MODEL_2c9a42d2f6024641a427af4fcaf9ff3d"
            ],
            "layout": "IPY_MODEL_1fa292f59e334f528888d6dde3bdb5b6"
          }
        },
        "0af8fe7f487a44dda20c99d97fbb9853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e32b0bf7ad64d7dbc996dc8dde9dba1",
            "placeholder": "​",
            "style": "IPY_MODEL_f536c1a57eab4e438bf867befa127733",
            "value": " 38141952/? [00:03&lt;00:00, 18282719.92it/s]"
          }
        },
        "1fa292f59e334f528888d6dde3bdb5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c9a42d2f6024641a427af4fcaf9ff3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bafb0fd97fc04fb0b850568b086af00f",
            "placeholder": "​",
            "style": "IPY_MODEL_9f634c50036e4a09a209976b41d4b30f",
            "value": " 130864128/? [00:07&lt;00:00, 21880297.53it/s]"
          }
        },
        "364060ffa5094011bac4933d36394c32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c7113e61d2a459bab73e7a5a89a6753": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8de305ca6b894a84820688eb8bc9ee41",
            "placeholder": "​",
            "style": "IPY_MODEL_c7cbf35c989e4fb5aacb73bb9f2709c1",
            "value": ""
          }
        },
        "404beecd514e4e9890ae736b8eabeb95": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c10bca5c4d04f5697d377a65f04df9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a66cc7415fe14862abb0b1e20903c705",
            "max": 130863613,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_000fde2d72f5492982d0f1207f9866cb",
            "value": 130863613
          }
        },
        "6e32b0bf7ad64d7dbc996dc8dde9dba1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8624d2ab2a0d41838529f8da5374b87c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8de305ca6b894a84820688eb8bc9ee41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "997243a6c2a14d6e81dc31aab3a81d71": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7fc57f81eef41449c35d80cc33339e6",
              "IPY_MODEL_ced68f55d587469cbf09c2fb5cab3c4e",
              "IPY_MODEL_0af8fe7f487a44dda20c99d97fbb9853"
            ],
            "layout": "IPY_MODEL_404beecd514e4e9890ae736b8eabeb95"
          }
        },
        "9f634c50036e4a09a209976b41d4b30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a66cc7415fe14862abb0b1e20903c705": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bafb0fd97fc04fb0b850568b086af00f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cbf35c989e4fb5aacb73bb9f2709c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ced68f55d587469cbf09c2fb5cab3c4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_364060ffa5094011bac4933d36394c32",
            "max": 38141465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8624d2ab2a0d41838529f8da5374b87c",
            "value": 38141465
          }
        },
        "d61a0b85e864432faab60bf0747bca1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7fc57f81eef41449c35d80cc33339e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d61a0b85e864432faab60bf0747bca1c",
            "placeholder": "​",
            "style": "IPY_MODEL_f85b9f780aba4454b03703addf466e47",
            "value": ""
          }
        },
        "f536c1a57eab4e438bf867befa127733": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f85b9f780aba4454b03703addf466e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
